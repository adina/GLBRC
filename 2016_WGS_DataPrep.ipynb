{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from glob import glob\n",
    "from pandas import DataFrame, read_csv, Series, to_datetime\n",
    "from pickle import dump, load\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.collections import LineCollection\n",
    "from sklearn import manifold\n",
    "from sklearn.metrics import euclidean_distances\n",
    "from random import randint \n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "def comma(number): return \"{:,}\".format(number)\n",
    "def scolor(i,n,pickColor): \n",
    "    scalar = 255 - int((i/float(n))*120) \n",
    "    if pickColor: return '#%02X%02X%02X' % (128,scalar,128)\n",
    "    return '#%02X%02X%02X' % (75,scalar,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><a id='outline'>Project Outline</a></h1>\n",
    "\n",
    "* [Metadata](#meta)\n",
    "* [Sequencing Overview](#analysis)\n",
    "    *  [Contig Occupency](#occon)\n",
    "*  [NMDS of annotated contigs](#nmds)\n",
    "  *  [All Crops](#anmds)\n",
    "  *  [Switchgrass](#sgnmds)\n",
    "  *  [Miscanthus](#msnmds)\n",
    "*  [Function Analysis](#metaT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id=\"meta\">GLBRC Metadata</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reads_file_name</th>\n",
       "      <th>treatment</th>\n",
       "      <th>plot_name</th>\n",
       "      <th>rep</th>\n",
       "      <th>sampling_date</th>\n",
       "      <th>Sampling Time</th>\n",
       "      <th>type</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nucleic_acid_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>G5R1_NF_09MAY2016_LD1</th>\n",
       "      <td>11425.5.206700.GCCTTGT-AACAAGG.fastq.gz</td>\n",
       "      <td>nitrogen free</td>\n",
       "      <td>G5R1_NF</td>\n",
       "      <td>1</td>\n",
       "      <td>5/9/16</td>\n",
       "      <td>12:00</td>\n",
       "      <td>G5</td>\n",
       "      <td>2016-05-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G5R2_NF_09MAY2016_LD1</th>\n",
       "      <td>11425.5.206700.CTGACAC-TGTGTCA.fastq.gz</td>\n",
       "      <td>nitrogen free</td>\n",
       "      <td>G5R2_NF</td>\n",
       "      <td>2</td>\n",
       "      <td>5/9/16</td>\n",
       "      <td>14:43</td>\n",
       "      <td>G5</td>\n",
       "      <td>2016-05-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G5R3_NF_09MAY2016_LD1</th>\n",
       "      <td>11425.3.206650.CCAGTGT-AACACTG.fastq.gz</td>\n",
       "      <td>nitrogen free</td>\n",
       "      <td>G5R3_NF</td>\n",
       "      <td>3</td>\n",
       "      <td>5/9/16</td>\n",
       "      <td>15:26</td>\n",
       "      <td>G5</td>\n",
       "      <td>2016-05-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G5R4_NF_09MAY2016_LD1</th>\n",
       "      <td>11425.5.206700.TGTACAC-GGTGTAC.fastq.gz</td>\n",
       "      <td>nitrogen free</td>\n",
       "      <td>G5R4_NF</td>\n",
       "      <td>4</td>\n",
       "      <td>5/9/16</td>\n",
       "      <td>13:56</td>\n",
       "      <td>G5</td>\n",
       "      <td>2016-05-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G5R1_MAIN_09MAY2016_LD1</th>\n",
       "      <td>11425.3.206650.GAGCTCA-TTGAGCT.fastq.gz</td>\n",
       "      <td>standard fertilization</td>\n",
       "      <td>G5R1_MAIN</td>\n",
       "      <td>1</td>\n",
       "      <td>5/9/16</td>\n",
       "      <td>12:00</td>\n",
       "      <td>G5</td>\n",
       "      <td>2016-05-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 reads_file_name  \\\n",
       "nucleic_acid_name                                                  \n",
       "G5R1_NF_09MAY2016_LD1    11425.5.206700.GCCTTGT-AACAAGG.fastq.gz   \n",
       "G5R2_NF_09MAY2016_LD1    11425.5.206700.CTGACAC-TGTGTCA.fastq.gz   \n",
       "G5R3_NF_09MAY2016_LD1    11425.3.206650.CCAGTGT-AACACTG.fastq.gz   \n",
       "G5R4_NF_09MAY2016_LD1    11425.5.206700.TGTACAC-GGTGTAC.fastq.gz   \n",
       "G5R1_MAIN_09MAY2016_LD1  11425.3.206650.GAGCTCA-TTGAGCT.fastq.gz   \n",
       "\n",
       "                                      treatment  plot_name  rep sampling_date  \\\n",
       "nucleic_acid_name                                                               \n",
       "G5R1_NF_09MAY2016_LD1             nitrogen free    G5R1_NF    1        5/9/16   \n",
       "G5R2_NF_09MAY2016_LD1             nitrogen free    G5R2_NF    2        5/9/16   \n",
       "G5R3_NF_09MAY2016_LD1             nitrogen free    G5R3_NF    3        5/9/16   \n",
       "G5R4_NF_09MAY2016_LD1             nitrogen free    G5R4_NF    4        5/9/16   \n",
       "G5R1_MAIN_09MAY2016_LD1  standard fertilization  G5R1_MAIN    1        5/9/16   \n",
       "\n",
       "                        Sampling Time type       Date  \n",
       "nucleic_acid_name                                      \n",
       "G5R1_NF_09MAY2016_LD1           12:00   G5 2016-05-09  \n",
       "G5R2_NF_09MAY2016_LD1           14:43   G5 2016-05-09  \n",
       "G5R3_NF_09MAY2016_LD1           15:26   G5 2016-05-09  \n",
       "G5R4_NF_09MAY2016_LD1           13:56   G5 2016-05-09  \n",
       "G5R1_MAIN_09MAY2016_LD1         12:00   G5 2016-05-09  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = read_csv(\"metadata/GLBRC_MetaG_Metadata.tsv\",sep='\\t')\n",
    "metadata.set_index(\"nucleic_acid_name\",inplace=True)\n",
    "metadata.drop([\"source\",\"sampling ID\",\"sequencing_type\",\"height_mean_cm\",\"air_temp_c\"],axis=1,inplace=True)\n",
    "\n",
    "for id in metadata.index: metadata.loc[id,\"type\"] = metadata[metadata.index == id].plot_name[0][0:2]\n",
    "metadata['Date'] = to_datetime(metadata.sampling_date)\n",
    "metadata=metadata.sort_values(by=[\"type\",\"Date\",\"treatment\",\"plot_name\"])\n",
    "# metadata['JGI_File'] = metadata.index\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating links to the raw data files from JGI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir, path, system\n",
    "rawFiles = {}\n",
    "baseDir = \"/mnt/research/ShadeLab/Sequence/raw_sequence/GLBRC/metagenomes/\"\n",
    "dirs = listdir(baseDir)\n",
    "for dirName in dirs:\n",
    "    rawDir = path.join(baseDir,dirName,\"Raw_Data/\")\n",
    "    fastq = listdir(rawDir)[0]\n",
    "    rawFiles[fastq] = path.join(rawDir,fastq)\n",
    "metaGUnpaired = \"/mnt/research/ShadeLab/GLBRC/mapping/metaG/unpaired/%s.fastq.gz\"\n",
    "    \n",
    "for readFName,row in metadata.iterrows():\n",
    "    if readFName not in rawFiles:\n",
    "        print(\"No fastq for \"+readFileName)\n",
    "        continue\n",
    "    system(\"ln -s %s %s\" % (rawFiles[readFName],metaGUnpaired %(row.loc['nucleic_acid_name'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id=\"analysis\">Sequence Mapping Overview</a></h2>\n",
    "<h4>Host organism reads removal</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_reads</th>\n",
       "      <th>paired_total</th>\n",
       "      <th>paired_aligned_none</th>\n",
       "      <th>paired_aligned_one</th>\n",
       "      <th>paired_aligned_multi</th>\n",
       "      <th>paired_aligned_discord_one</th>\n",
       "      <th>paired_aligned_mate_none</th>\n",
       "      <th>paired_aligned_mate_one</th>\n",
       "      <th>paired_aligned_mate_multi</th>\n",
       "      <th>overall_alignment_rate</th>\n",
       "      <th>paired_aligned_mate_multi_halved</th>\n",
       "      <th>paired_aligned_mate_none_halved</th>\n",
       "      <th>paired_aligned_mate_one_halved</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sample</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>G5R1_MAIN_01AUG2016_LD1.stat</th>\n",
       "      <td>5975345</td>\n",
       "      <td>5924069</td>\n",
       "      <td>1456152</td>\n",
       "      <td>1445666</td>\n",
       "      <td>3022251</td>\n",
       "      <td>33663</td>\n",
       "      <td>2084849</td>\n",
       "      <td>256653</td>\n",
       "      <td>503476</td>\n",
       "      <td>82.40</td>\n",
       "      <td>251738.0</td>\n",
       "      <td>1042424.5</td>\n",
       "      <td>128326.5</td>\n",
       "      <td>G5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G5R1_MAIN_03OCT2016_LD1.stat</th>\n",
       "      <td>8615788</td>\n",
       "      <td>8528146</td>\n",
       "      <td>6957303</td>\n",
       "      <td>457799</td>\n",
       "      <td>1113044</td>\n",
       "      <td>9540</td>\n",
       "      <td>13668862</td>\n",
       "      <td>73292</td>\n",
       "      <td>153372</td>\n",
       "      <td>19.82</td>\n",
       "      <td>76686.0</td>\n",
       "      <td>6834431.0</td>\n",
       "      <td>36646.0</td>\n",
       "      <td>G5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G5R1_MAIN_09MAY2016_LD1.stat</th>\n",
       "      <td>6888824</td>\n",
       "      <td>6828883</td>\n",
       "      <td>2222145</td>\n",
       "      <td>1508784</td>\n",
       "      <td>3097954</td>\n",
       "      <td>36624</td>\n",
       "      <td>3624079</td>\n",
       "      <td>268840</td>\n",
       "      <td>478123</td>\n",
       "      <td>73.46</td>\n",
       "      <td>239061.5</td>\n",
       "      <td>1812039.5</td>\n",
       "      <td>134420.0</td>\n",
       "      <td>G5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G5R1_MAIN_12JUL2016_LD1.stat</th>\n",
       "      <td>10182583</td>\n",
       "      <td>10042351</td>\n",
       "      <td>2022000</td>\n",
       "      <td>2594162</td>\n",
       "      <td>5426189</td>\n",
       "      <td>68503</td>\n",
       "      <td>2384468</td>\n",
       "      <td>495577</td>\n",
       "      <td>1026949</td>\n",
       "      <td>88.09</td>\n",
       "      <td>513474.5</td>\n",
       "      <td>1192234.0</td>\n",
       "      <td>247788.5</td>\n",
       "      <td>G5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G5R1_MAIN_12SEP2016_LD1.stat</th>\n",
       "      <td>8024208</td>\n",
       "      <td>7957864</td>\n",
       "      <td>4843759</td>\n",
       "      <td>1002139</td>\n",
       "      <td>2111966</td>\n",
       "      <td>18921</td>\n",
       "      <td>9179491</td>\n",
       "      <td>168248</td>\n",
       "      <td>301937</td>\n",
       "      <td>42.27</td>\n",
       "      <td>150968.5</td>\n",
       "      <td>4589745.5</td>\n",
       "      <td>84124.0</td>\n",
       "      <td>G5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              total_reads  paired_total  paired_aligned_none  \\\n",
       "Sample                                                                         \n",
       "G5R1_MAIN_01AUG2016_LD1.stat      5975345       5924069              1456152   \n",
       "G5R1_MAIN_03OCT2016_LD1.stat      8615788       8528146              6957303   \n",
       "G5R1_MAIN_09MAY2016_LD1.stat      6888824       6828883              2222145   \n",
       "G5R1_MAIN_12JUL2016_LD1.stat     10182583      10042351              2022000   \n",
       "G5R1_MAIN_12SEP2016_LD1.stat      8024208       7957864              4843759   \n",
       "\n",
       "                              paired_aligned_one  paired_aligned_multi  \\\n",
       "Sample                                                                   \n",
       "G5R1_MAIN_01AUG2016_LD1.stat             1445666               3022251   \n",
       "G5R1_MAIN_03OCT2016_LD1.stat              457799               1113044   \n",
       "G5R1_MAIN_09MAY2016_LD1.stat             1508784               3097954   \n",
       "G5R1_MAIN_12JUL2016_LD1.stat             2594162               5426189   \n",
       "G5R1_MAIN_12SEP2016_LD1.stat             1002139               2111966   \n",
       "\n",
       "                              paired_aligned_discord_one  \\\n",
       "Sample                                                     \n",
       "G5R1_MAIN_01AUG2016_LD1.stat                       33663   \n",
       "G5R1_MAIN_03OCT2016_LD1.stat                        9540   \n",
       "G5R1_MAIN_09MAY2016_LD1.stat                       36624   \n",
       "G5R1_MAIN_12JUL2016_LD1.stat                       68503   \n",
       "G5R1_MAIN_12SEP2016_LD1.stat                       18921   \n",
       "\n",
       "                              paired_aligned_mate_none  \\\n",
       "Sample                                                   \n",
       "G5R1_MAIN_01AUG2016_LD1.stat                   2084849   \n",
       "G5R1_MAIN_03OCT2016_LD1.stat                  13668862   \n",
       "G5R1_MAIN_09MAY2016_LD1.stat                   3624079   \n",
       "G5R1_MAIN_12JUL2016_LD1.stat                   2384468   \n",
       "G5R1_MAIN_12SEP2016_LD1.stat                   9179491   \n",
       "\n",
       "                              paired_aligned_mate_one  \\\n",
       "Sample                                                  \n",
       "G5R1_MAIN_01AUG2016_LD1.stat                   256653   \n",
       "G5R1_MAIN_03OCT2016_LD1.stat                    73292   \n",
       "G5R1_MAIN_09MAY2016_LD1.stat                   268840   \n",
       "G5R1_MAIN_12JUL2016_LD1.stat                   495577   \n",
       "G5R1_MAIN_12SEP2016_LD1.stat                   168248   \n",
       "\n",
       "                              paired_aligned_mate_multi  \\\n",
       "Sample                                                    \n",
       "G5R1_MAIN_01AUG2016_LD1.stat                     503476   \n",
       "G5R1_MAIN_03OCT2016_LD1.stat                     153372   \n",
       "G5R1_MAIN_09MAY2016_LD1.stat                     478123   \n",
       "G5R1_MAIN_12JUL2016_LD1.stat                    1026949   \n",
       "G5R1_MAIN_12SEP2016_LD1.stat                     301937   \n",
       "\n",
       "                              overall_alignment_rate  \\\n",
       "Sample                                                 \n",
       "G5R1_MAIN_01AUG2016_LD1.stat                   82.40   \n",
       "G5R1_MAIN_03OCT2016_LD1.stat                   19.82   \n",
       "G5R1_MAIN_09MAY2016_LD1.stat                   73.46   \n",
       "G5R1_MAIN_12JUL2016_LD1.stat                   88.09   \n",
       "G5R1_MAIN_12SEP2016_LD1.stat                   42.27   \n",
       "\n",
       "                              paired_aligned_mate_multi_halved  \\\n",
       "Sample                                                           \n",
       "G5R1_MAIN_01AUG2016_LD1.stat                          251738.0   \n",
       "G5R1_MAIN_03OCT2016_LD1.stat                           76686.0   \n",
       "G5R1_MAIN_09MAY2016_LD1.stat                          239061.5   \n",
       "G5R1_MAIN_12JUL2016_LD1.stat                          513474.5   \n",
       "G5R1_MAIN_12SEP2016_LD1.stat                          150968.5   \n",
       "\n",
       "                              paired_aligned_mate_none_halved  \\\n",
       "Sample                                                          \n",
       "G5R1_MAIN_01AUG2016_LD1.stat                        1042424.5   \n",
       "G5R1_MAIN_03OCT2016_LD1.stat                        6834431.0   \n",
       "G5R1_MAIN_09MAY2016_LD1.stat                        1812039.5   \n",
       "G5R1_MAIN_12JUL2016_LD1.stat                        1192234.0   \n",
       "G5R1_MAIN_12SEP2016_LD1.stat                        4589745.5   \n",
       "\n",
       "                              paired_aligned_mate_one_halved type  \n",
       "Sample                                                             \n",
       "G5R1_MAIN_01AUG2016_LD1.stat                        128326.5   G5  \n",
       "G5R1_MAIN_03OCT2016_LD1.stat                         36646.0   G5  \n",
       "G5R1_MAIN_09MAY2016_LD1.stat                        134420.0   G5  \n",
       "G5R1_MAIN_12JUL2016_LD1.stat                        247788.5   G5  \n",
       "G5R1_MAIN_12SEP2016_LD1.stat                         84124.0   G5  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hostMapping = read_csv(\"mapping/metaG/hostRemoval/multiqc_bowtie2.txt\",sep='\\t')\n",
    "hostMapping.set_index(\"Sample\",inplace=True)\n",
    "hostMapping['type'] = \"\"\n",
    "for id in hostMapping.index: hostMapping.at[id,\"type\"] = id[0:2]\n",
    "hostMapping[\"sample_name\"]=\"\"\n",
    "for id in hostMapping.index: hostMapping.at[id,\"sample_name\"] = id.replace(\".stat\",\"\")\n",
    "hostMapping.set_index(\"sample_name\",inplace=True)\n",
    "hostMapping.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "SGData = hostMapping[hostMapping['type']=='G5']\n",
    "MiscanData = hostMapping[hostMapping['type']=='G6']\n",
    "\n",
    "sgTotal = SGData['total_reads'].sum()\n",
    "miscanTotatl = MiscanData['total_reads'].sum()\n",
    "\n",
    "sgBact = SGData['paired_aligned_none'].sum()\n",
    "miscanBact = MiscanData['paired_aligned_none'].sum()\n",
    "\n",
    "(sgTotal-sgBact)/sgTotal*100\n",
    "\n",
    "(miscanTotatl-miscanBact)/miscanTotatl*100\n",
    "\n",
    "comma(SGData['paired_aligned_none'].sum() +MiscanData['paired_aligned_none'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alignment of non-host related reads to metagenomic assembly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_reads</th>\n",
       "      <th>paired_total</th>\n",
       "      <th>paired_aligned_none</th>\n",
       "      <th>paired_aligned_one</th>\n",
       "      <th>paired_aligned_multi</th>\n",
       "      <th>paired_aligned_discord_one</th>\n",
       "      <th>paired_aligned_mate_none</th>\n",
       "      <th>paired_aligned_mate_one</th>\n",
       "      <th>paired_aligned_mate_multi</th>\n",
       "      <th>overall_alignment_rate</th>\n",
       "      <th>paired_aligned_mate_multi_halved</th>\n",
       "      <th>paired_aligned_mate_none_halved</th>\n",
       "      <th>paired_aligned_mate_one_halved</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>G5R1_MAIN_01AUG2016_LD1</th>\n",
       "      <td>801996</td>\n",
       "      <td>801996</td>\n",
       "      <td>236096</td>\n",
       "      <td>393846</td>\n",
       "      <td>172054</td>\n",
       "      <td>12008</td>\n",
       "      <td>332039</td>\n",
       "      <td>46895</td>\n",
       "      <td>69242</td>\n",
       "      <td>79.30</td>\n",
       "      <td>34621.0</td>\n",
       "      <td>166019.5</td>\n",
       "      <td>23447.5</td>\n",
       "      <td>G5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G5R1_MAIN_03OCT2016_LD1</th>\n",
       "      <td>6753815</td>\n",
       "      <td>6753815</td>\n",
       "      <td>1176079</td>\n",
       "      <td>3127763</td>\n",
       "      <td>2449973</td>\n",
       "      <td>60231</td>\n",
       "      <td>1623641</td>\n",
       "      <td>208720</td>\n",
       "      <td>399335</td>\n",
       "      <td>87.98</td>\n",
       "      <td>199667.5</td>\n",
       "      <td>811820.5</td>\n",
       "      <td>104360.0</td>\n",
       "      <td>G5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G5R1_MAIN_09MAY2016_LD1</th>\n",
       "      <td>1572819</td>\n",
       "      <td>1572819</td>\n",
       "      <td>428877</td>\n",
       "      <td>376661</td>\n",
       "      <td>767281</td>\n",
       "      <td>13648</td>\n",
       "      <td>507423</td>\n",
       "      <td>90724</td>\n",
       "      <td>232311</td>\n",
       "      <td>83.87</td>\n",
       "      <td>116155.5</td>\n",
       "      <td>253711.5</td>\n",
       "      <td>45362.0</td>\n",
       "      <td>G5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G5R1_MAIN_12JUL2016_LD1</th>\n",
       "      <td>729303</td>\n",
       "      <td>729303</td>\n",
       "      <td>191014</td>\n",
       "      <td>368352</td>\n",
       "      <td>169937</td>\n",
       "      <td>12991</td>\n",
       "      <td>218236</td>\n",
       "      <td>56798</td>\n",
       "      <td>81012</td>\n",
       "      <td>85.04</td>\n",
       "      <td>40506.0</td>\n",
       "      <td>109118.0</td>\n",
       "      <td>28399.0</td>\n",
       "      <td>G5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G5R1_MAIN_12SEP2016_LD1</th>\n",
       "      <td>4427118</td>\n",
       "      <td>4427118</td>\n",
       "      <td>815340</td>\n",
       "      <td>2046133</td>\n",
       "      <td>1565645</td>\n",
       "      <td>41191</td>\n",
       "      <td>1014794</td>\n",
       "      <td>173568</td>\n",
       "      <td>359936</td>\n",
       "      <td>88.54</td>\n",
       "      <td>179968.0</td>\n",
       "      <td>507397.0</td>\n",
       "      <td>86784.0</td>\n",
       "      <td>G5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         total_reads  paired_total  paired_aligned_none  \\\n",
       "sample_name                                                               \n",
       "G5R1_MAIN_01AUG2016_LD1       801996        801996               236096   \n",
       "G5R1_MAIN_03OCT2016_LD1      6753815       6753815              1176079   \n",
       "G5R1_MAIN_09MAY2016_LD1      1572819       1572819               428877   \n",
       "G5R1_MAIN_12JUL2016_LD1       729303        729303               191014   \n",
       "G5R1_MAIN_12SEP2016_LD1      4427118       4427118               815340   \n",
       "\n",
       "                         paired_aligned_one  paired_aligned_multi  \\\n",
       "sample_name                                                         \n",
       "G5R1_MAIN_01AUG2016_LD1              393846                172054   \n",
       "G5R1_MAIN_03OCT2016_LD1             3127763               2449973   \n",
       "G5R1_MAIN_09MAY2016_LD1              376661                767281   \n",
       "G5R1_MAIN_12JUL2016_LD1              368352                169937   \n",
       "G5R1_MAIN_12SEP2016_LD1             2046133               1565645   \n",
       "\n",
       "                         paired_aligned_discord_one  paired_aligned_mate_none  \\\n",
       "sample_name                                                                     \n",
       "G5R1_MAIN_01AUG2016_LD1                       12008                    332039   \n",
       "G5R1_MAIN_03OCT2016_LD1                       60231                   1623641   \n",
       "G5R1_MAIN_09MAY2016_LD1                       13648                    507423   \n",
       "G5R1_MAIN_12JUL2016_LD1                       12991                    218236   \n",
       "G5R1_MAIN_12SEP2016_LD1                       41191                   1014794   \n",
       "\n",
       "                         paired_aligned_mate_one  paired_aligned_mate_multi  \\\n",
       "sample_name                                                                   \n",
       "G5R1_MAIN_01AUG2016_LD1                    46895                      69242   \n",
       "G5R1_MAIN_03OCT2016_LD1                   208720                     399335   \n",
       "G5R1_MAIN_09MAY2016_LD1                    90724                     232311   \n",
       "G5R1_MAIN_12JUL2016_LD1                    56798                      81012   \n",
       "G5R1_MAIN_12SEP2016_LD1                   173568                     359936   \n",
       "\n",
       "                         overall_alignment_rate  \\\n",
       "sample_name                                       \n",
       "G5R1_MAIN_01AUG2016_LD1                   79.30   \n",
       "G5R1_MAIN_03OCT2016_LD1                   87.98   \n",
       "G5R1_MAIN_09MAY2016_LD1                   83.87   \n",
       "G5R1_MAIN_12JUL2016_LD1                   85.04   \n",
       "G5R1_MAIN_12SEP2016_LD1                   88.54   \n",
       "\n",
       "                         paired_aligned_mate_multi_halved  \\\n",
       "sample_name                                                 \n",
       "G5R1_MAIN_01AUG2016_LD1                           34621.0   \n",
       "G5R1_MAIN_03OCT2016_LD1                          199667.5   \n",
       "G5R1_MAIN_09MAY2016_LD1                          116155.5   \n",
       "G5R1_MAIN_12JUL2016_LD1                           40506.0   \n",
       "G5R1_MAIN_12SEP2016_LD1                          179968.0   \n",
       "\n",
       "                         paired_aligned_mate_none_halved  \\\n",
       "sample_name                                                \n",
       "G5R1_MAIN_01AUG2016_LD1                         166019.5   \n",
       "G5R1_MAIN_03OCT2016_LD1                         811820.5   \n",
       "G5R1_MAIN_09MAY2016_LD1                         253711.5   \n",
       "G5R1_MAIN_12JUL2016_LD1                         109118.0   \n",
       "G5R1_MAIN_12SEP2016_LD1                         507397.0   \n",
       "\n",
       "                         paired_aligned_mate_one_halved type  \n",
       "sample_name                                                   \n",
       "G5R1_MAIN_01AUG2016_LD1                         23447.5   G5  \n",
       "G5R1_MAIN_03OCT2016_LD1                        104360.0   G5  \n",
       "G5R1_MAIN_09MAY2016_LD1                         45362.0   G5  \n",
       "G5R1_MAIN_12JUL2016_LD1                         28399.0   G5  \n",
       "G5R1_MAIN_12SEP2016_LD1                         86784.0   G5  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqMapping = read_csv(\"mapping/metaG/fullAssembly/multiqc_data/multiqc_bowtie2.txt\",sep='\\t')\n",
    "seqMapping.set_index(\"Sample\",inplace=True)\n",
    "seqMapping['type'] = \"\"\n",
    "for id in seqMapping.index: seqMapping.at[id,\"type\"] = id[0:2]\n",
    "seqMapping[\"sample_name\"]=\"\"\n",
    "for id in seqMapping.index: seqMapping.at[id,\"sample_name\"] = id.replace(\".stat\",\"\")\n",
    "seqMapping.set_index(\"sample_name\",inplace=True)\n",
    "seqMapping.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "SGData = seqMapping[hostMapping['type']=='G5']\n",
    "MiscanData = seqMapping[hostMapping['type']=='G6']\n",
    "\n",
    "sgTotal = SGData['total_reads'].sum()\n",
    "miscanTotatl = MiscanData['total_reads'].sum()\n",
    "\n",
    "sgBact = SGData['paired_aligned_none'].sum()\n",
    "miscanBact = MiscanData['paired_aligned_none'].sum()\n",
    "\n",
    "print('SG %% aligned: %.2f' % ((sgTotal-sgBact)/sgTotal*100),comma(sgTotal))\n",
    "print('Miscanthus %% aligned: %.2f' % ((miscanTotatl-miscanBact)/miscanTotatl*100),comma(miscanTotatl))\n",
    "print(comma(SGData['paired_aligned_none'].sum() +MiscanData['paired_aligned_none'].sum()))\n",
    "\n",
    "#MetaG\n",
    "metaG = read_csv(\"mapping/metaG/annotatedContigs/logs/multiqc_data/mqc_trimmomatic_plot_1.txt\",sep=\"\\t\")\n",
    "metaG.set_index('Sample',inplace=True)\n",
    "print(comma(metaG['Surviving Reads'].sum()))\n",
    "\n",
    "metaT = read_csv(\"mapping/metaT/fullAssembly/logs/multiqc_data/multiqc_trimmomatic.txt\",sep=\"\\t\")\n",
    "metaT.set_index('Sample',inplace=True)\n",
    "print(comma(metaT['surviving'].sum())\n",
    "\n",
    "metaT['Base'],metaG['Base'] = '',''\n",
    "\n",
    "for sampleID in metaG.index:\n",
    "    metaG.at[sampleID,'Base'] = sampleID[:sampleID.rfind('_')]\n",
    "for sampleID in metaT.index:\n",
    "    metaT.at[sampleID,'Base'] = sampleID[:sampleID.rfind('_')]\n",
    "\n",
    "metaT.set_index(\"Base\",inplace=True)\n",
    "metaG.set_index(\"Base\",inplace=True)\n",
    "\n",
    "comma(metaT['surviving'].sum()-metaG['Surviving Reads'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sampleID in ids.intersection(ids2):\n",
    "#     print(sampleID,'\\t',comma(int(metaT.at[sampleID,'surviving'])),'\\t',comma(int(metaG.at[sampleID,'Surviving Reads'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_csv(\"mapping/metaG/annotatedContigs/logs/multiqc_data/mqc_bowtie2_pe_plot_1.txt\",sep=\"\\t\")\n",
    "data[\"TotalSampleReads\"] = data.sum(axis=1)\n",
    "#data[[\"PE mapped uniquely\",\"PE mapped discordantly uniquely\",\"PE multimapped\"]]/data[\"TotalSampleReads\"] \n",
    "print(\"(%i, %i)\" % (data.shape, metadata.shape))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KEGG Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level1</th>\n",
       "      <th>level2</th>\n",
       "      <th>level3</th>\n",
       "      <th>function</th>\n",
       "      <th>id</th>\n",
       "      <th>EC#</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>HK; hexokinase</td>\n",
       "      <td>K00844</td>\n",
       "      <td>EC:2.7.1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>GCK; glucokinase</td>\n",
       "      <td>K12407</td>\n",
       "      <td>EC:2.7.1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>glk; glucokinase</td>\n",
       "      <td>K00845</td>\n",
       "      <td>EC:2.7.1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>GPI, pgi; glucose-6-phosphate isomerase</td>\n",
       "      <td>K01810</td>\n",
       "      <td>EC:5.3.1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>pgi1; glucose-6-phosphate isomerase, archaeal</td>\n",
       "      <td>K06859</td>\n",
       "      <td>EC:5.3.1.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       level1                   level2  \\\n",
       "0  Metabolism  Carbohydrate metabolism   \n",
       "1  Metabolism  Carbohydrate metabolism   \n",
       "2  Metabolism  Carbohydrate metabolism   \n",
       "3  Metabolism  Carbohydrate metabolism   \n",
       "4  Metabolism  Carbohydrate metabolism   \n",
       "\n",
       "                                        level3  \\\n",
       "0  Glycolysis / Gluconeogenesis [PATH:ko00010]   \n",
       "1  Glycolysis / Gluconeogenesis [PATH:ko00010]   \n",
       "2  Glycolysis / Gluconeogenesis [PATH:ko00010]   \n",
       "3  Glycolysis / Gluconeogenesis [PATH:ko00010]   \n",
       "4  Glycolysis / Gluconeogenesis [PATH:ko00010]   \n",
       "\n",
       "                                        function      id         EC#  \n",
       "0                                 HK; hexokinase  K00844  EC:2.7.1.1  \n",
       "1                               GCK; glucokinase  K12407  EC:2.7.1.2  \n",
       "2                               glk; glucokinase  K00845  EC:2.7.1.2  \n",
       "3        GPI, pgi; glucose-6-phosphate isomerase  K01810  EC:5.3.1.9  \n",
       "4  pgi1; glucose-6-phosphate isomerase, archaeal  K06859  EC:5.3.1.9  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotation_hierarchy = read_csv(\"annotations/KeggAnnotationTable_filtered.tsv\",sep='\\t')\n",
    "annotation_hierarchy[\"EC#\"] = \"\"\n",
    "for i in annotation_hierarchy.index:\n",
    "    function = annotation_hierarchy.at[i,'function']\n",
    "    ecNumIndex = function.rfind(\" [EC\")\n",
    "    if ecNumIndex != -1:\n",
    "        annotation_hierarchy.at[i,'EC#'] = function[ecNumIndex+2:-1]\n",
    "        annotation_hierarchy.at[i,'function'] = function[:ecNumIndex]\n",
    "annotation_hierarchy.head(5)\n",
    "\n",
    "# (\"annotations/MetagenomicAssemblyAnnotations.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KO_NUM</th>\n",
       "      <th>GENE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>K14021</td>\n",
       "      <td>hsa:578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K14018</td>\n",
       "      <td>hsa:9373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K04429</td>\n",
       "      <td>hsa:9344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K04366</td>\n",
       "      <td>hsa:5894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K04365</td>\n",
       "      <td>hsa:673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   KO_NUM      GENE\n",
       "0  K14021   hsa:578\n",
       "1  K14018  hsa:9373\n",
       "2  K04429  hsa:9344\n",
       "3  K04366  hsa:5894\n",
       "4  K04365   hsa:673"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ko_map = read_csv(\"annotations/ko/ko_genes.list\",sep='\\t')\n",
    "ko_map.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19844, 21711, 18929)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(annotation_hierarchy.id.unique()),len(set(ko_map.KO_NUM.unique())),len(set(ko_map.KO_NUM.unique()).intersection(annotation_hierarchy.id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level1</th>\n",
       "      <th>level2</th>\n",
       "      <th>level3</th>\n",
       "      <th>function</th>\n",
       "      <th>id</th>\n",
       "      <th>EC#</th>\n",
       "      <th>KO_NUM</th>\n",
       "      <th>GENE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>HK; hexokinase</td>\n",
       "      <td>K00844</td>\n",
       "      <td>EC:2.7.1.1</td>\n",
       "      <td>K00844</td>\n",
       "      <td>hsa:3101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>HK; hexokinase</td>\n",
       "      <td>K00844</td>\n",
       "      <td>EC:2.7.1.1</td>\n",
       "      <td>K00844</td>\n",
       "      <td>hsa:3098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>HK; hexokinase</td>\n",
       "      <td>K00844</td>\n",
       "      <td>EC:2.7.1.1</td>\n",
       "      <td>K00844</td>\n",
       "      <td>hsa:3099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>HK; hexokinase</td>\n",
       "      <td>K00844</td>\n",
       "      <td>EC:2.7.1.1</td>\n",
       "      <td>K00844</td>\n",
       "      <td>hsa:80201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>HK; hexokinase</td>\n",
       "      <td>K00844</td>\n",
       "      <td>EC:2.7.1.1</td>\n",
       "      <td>K00844</td>\n",
       "      <td>ptr:462298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       level1                   level2  \\\n",
       "0  Metabolism  Carbohydrate metabolism   \n",
       "1  Metabolism  Carbohydrate metabolism   \n",
       "2  Metabolism  Carbohydrate metabolism   \n",
       "3  Metabolism  Carbohydrate metabolism   \n",
       "4  Metabolism  Carbohydrate metabolism   \n",
       "\n",
       "                                        level3        function      id  \\\n",
       "0  Glycolysis / Gluconeogenesis [PATH:ko00010]  HK; hexokinase  K00844   \n",
       "1  Glycolysis / Gluconeogenesis [PATH:ko00010]  HK; hexokinase  K00844   \n",
       "2  Glycolysis / Gluconeogenesis [PATH:ko00010]  HK; hexokinase  K00844   \n",
       "3  Glycolysis / Gluconeogenesis [PATH:ko00010]  HK; hexokinase  K00844   \n",
       "4  Glycolysis / Gluconeogenesis [PATH:ko00010]  HK; hexokinase  K00844   \n",
       "\n",
       "          EC#  KO_NUM        GENE  \n",
       "0  EC:2.7.1.1  K00844    hsa:3101  \n",
       "1  EC:2.7.1.1  K00844    hsa:3098  \n",
       "2  EC:2.7.1.1  K00844    hsa:3099  \n",
       "3  EC:2.7.1.1  K00844   hsa:80201  \n",
       "4  EC:2.7.1.1  K00844  ptr:462298  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.merge(annotation_hierarchy, ko_map, left_on='id',right_on='KO_NUM', how='left')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the level 3 table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700982, 193017)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genes = set()\n",
    "for line in open(\"annotations/UniqFoundGenes.txt\"):\n",
    "    genes.add(line.strip())\n",
    "len(genes),len(genes.difference(ko_map.GENE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level1</th>\n",
       "      <th>level2</th>\n",
       "      <th>level3</th>\n",
       "      <th>function</th>\n",
       "      <th>id</th>\n",
       "      <th>EC#</th>\n",
       "      <th>KO_NUM</th>\n",
       "      <th>GENE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>HK; hexokinase</td>\n",
       "      <td>K00844</td>\n",
       "      <td>EC:2.7.1.1</td>\n",
       "      <td>K00844</td>\n",
       "      <td>hsa:3101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>HK; hexokinase</td>\n",
       "      <td>K00844</td>\n",
       "      <td>EC:2.7.1.1</td>\n",
       "      <td>K00844</td>\n",
       "      <td>hsa:3098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>HK; hexokinase</td>\n",
       "      <td>K00844</td>\n",
       "      <td>EC:2.7.1.1</td>\n",
       "      <td>K00844</td>\n",
       "      <td>hsa:3099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>HK; hexokinase</td>\n",
       "      <td>K00844</td>\n",
       "      <td>EC:2.7.1.1</td>\n",
       "      <td>K00844</td>\n",
       "      <td>hsa:80201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>HK; hexokinase</td>\n",
       "      <td>K00844</td>\n",
       "      <td>EC:2.7.1.1</td>\n",
       "      <td>K00844</td>\n",
       "      <td>ptr:462298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>HK; hexokinase</td>\n",
       "      <td>K00844</td>\n",
       "      <td>EC:2.7.1.1</td>\n",
       "      <td>K00844</td>\n",
       "      <td>ptr:450505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>HK; hexokinase</td>\n",
       "      <td>K00844</td>\n",
       "      <td>EC:2.7.1.1</td>\n",
       "      <td>K00844</td>\n",
       "      <td>ptr:741291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>HK; hexokinase</td>\n",
       "      <td>K00844</td>\n",
       "      <td>EC:2.7.1.1</td>\n",
       "      <td>K00844</td>\n",
       "      <td>ptr:450504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>HK; hexokinase</td>\n",
       "      <td>K00844</td>\n",
       "      <td>EC:2.7.1.1</td>\n",
       "      <td>K00844</td>\n",
       "      <td>pps:100990081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>HK; hexokinase</td>\n",
       "      <td>K00844</td>\n",
       "      <td>EC:2.7.1.1</td>\n",
       "      <td>K00844</td>\n",
       "      <td>pps:100983149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>HK; hexokinase</td>\n",
       "      <td>K00844</td>\n",
       "      <td>EC:2.7.1.1</td>\n",
       "      <td>K00844</td>\n",
       "      <td>pps:100969639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>HK; hexokinase</td>\n",
       "      <td>K00844</td>\n",
       "      <td>EC:2.7.1.1</td>\n",
       "      <td>K00844</td>\n",
       "      <td>pps:100969975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>HK; hexokinase</td>\n",
       "      <td>K00844</td>\n",
       "      <td>EC:2.7.1.1</td>\n",
       "      <td>K00844</td>\n",
       "      <td>ggo:101146050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>HK; hexokinase</td>\n",
       "      <td>K00844</td>\n",
       "      <td>EC:2.7.1.1</td>\n",
       "      <td>K00844</td>\n",
       "      <td>ggo:101127052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>HK; hexokinase</td>\n",
       "      <td>K00844</td>\n",
       "      <td>EC:2.7.1.1</td>\n",
       "      <td>K00844</td>\n",
       "      <td>ggo:101131029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>HK; hexokinase</td>\n",
       "      <td>K00844</td>\n",
       "      <td>EC:2.7.1.1</td>\n",
       "      <td>K00844</td>\n",
       "      <td>ggo:101125395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>HK; hexokinase</td>\n",
       "      <td>K00844</td>\n",
       "      <td>EC:2.7.1.1</td>\n",
       "      <td>K00844</td>\n",
       "      <td>pon:100460834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>HK; hexokinase</td>\n",
       "      <td>K00844</td>\n",
       "      <td>EC:2.7.1.1</td>\n",
       "      <td>K00844</td>\n",
       "      <td>pon:100433183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>HK; hexokinase</td>\n",
       "      <td>K00844</td>\n",
       "      <td>EC:2.7.1.1</td>\n",
       "      <td>K00844</td>\n",
       "      <td>pon:100458288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>HK; hexokinase</td>\n",
       "      <td>K00844</td>\n",
       "      <td>EC:2.7.1.1</td>\n",
       "      <td>K00844</td>\n",
       "      <td>pon:100172246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>HK; hexokinase</td>\n",
       "      <td>K00844</td>\n",
       "      <td>EC:2.7.1.1</td>\n",
       "      <td>K00844</td>\n",
       "      <td>nle:100591401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>HK; hexokinase</td>\n",
       "      <td>K00844</td>\n",
       "      <td>EC:2.7.1.1</td>\n",
       "      <td>K00844</td>\n",
       "      <td>nle:100591323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>HK; hexokinase</td>\n",
       "      <td>K00844</td>\n",
       "      <td>EC:2.7.1.1</td>\n",
       "      <td>K00844</td>\n",
       "      <td>nle:100595352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>HK; hexokinase</td>\n",
       "      <td>K00844</td>\n",
       "      <td>EC:2.7.1.1</td>\n",
       "      <td>K00844</td>\n",
       "      <td>nle:100595917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>HK; hexokinase</td>\n",
       "      <td>K00844</td>\n",
       "      <td>EC:2.7.1.1</td>\n",
       "      <td>K00844</td>\n",
       "      <td>nle:100593006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>HK; hexokinase</td>\n",
       "      <td>K00844</td>\n",
       "      <td>EC:2.7.1.1</td>\n",
       "      <td>K00844</td>\n",
       "      <td>mcc:710479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>HK; hexokinase</td>\n",
       "      <td>K00844</td>\n",
       "      <td>EC:2.7.1.1</td>\n",
       "      <td>K00844</td>\n",
       "      <td>mcc:698120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>HK; hexokinase</td>\n",
       "      <td>K00844</td>\n",
       "      <td>EC:2.7.1.1</td>\n",
       "      <td>K00844</td>\n",
       "      <td>mcc:711922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>HK; hexokinase</td>\n",
       "      <td>K00844</td>\n",
       "      <td>EC:2.7.1.1</td>\n",
       "      <td>K00844</td>\n",
       "      <td>mcc:711995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>HK; hexokinase</td>\n",
       "      <td>K00844</td>\n",
       "      <td>EC:2.7.1.1</td>\n",
       "      <td>K00844</td>\n",
       "      <td>mcf:102121518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175262</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>PTS-Asc-EIIC, ascF; PTS system, beta-glucoside...</td>\n",
       "      <td>K02753</td>\n",
       "      <td></td>\n",
       "      <td>K02753</td>\n",
       "      <td>pam:PANA_4223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175263</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>PTS-Asc-EIIC, ascF; PTS system, beta-glucoside...</td>\n",
       "      <td>K02753</td>\n",
       "      <td></td>\n",
       "      <td>K02753</td>\n",
       "      <td>plf:PANA5342_p10044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175264</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>PTS-Asc-EIIC, ascF; PTS system, beta-glucoside...</td>\n",
       "      <td>K02753</td>\n",
       "      <td></td>\n",
       "      <td>K02753</td>\n",
       "      <td>paj:PAJ_p0065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175265</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>PTS-Asc-EIIC, ascF; PTS system, beta-glucoside...</td>\n",
       "      <td>K02753</td>\n",
       "      <td></td>\n",
       "      <td>K02753</td>\n",
       "      <td>paq:PAGR_p035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175266</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>PTS-Asc-EIIC, ascF; PTS system, beta-glucoside...</td>\n",
       "      <td>K02753</td>\n",
       "      <td></td>\n",
       "      <td>K02753</td>\n",
       "      <td>pva:Pvag_pPag30436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175267</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>PTS-Asc-EIIC, ascF; PTS system, beta-glucoside...</td>\n",
       "      <td>K02753</td>\n",
       "      <td></td>\n",
       "      <td>K02753</td>\n",
       "      <td>pao:Pat9b_5887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175268</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>PTS-Asc-EIIC, ascF; PTS system, beta-glucoside...</td>\n",
       "      <td>K02753</td>\n",
       "      <td></td>\n",
       "      <td>K02753</td>\n",
       "      <td>pant:PSNIH1_p01015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175269</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>PTS-Asc-EIIC, ascF; PTS system, beta-glucoside...</td>\n",
       "      <td>K02753</td>\n",
       "      <td></td>\n",
       "      <td>K02753</td>\n",
       "      <td>panp:PSNIH2_15450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175270</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>PTS-Asc-EIIC, ascF; PTS system, beta-glucoside...</td>\n",
       "      <td>K02753</td>\n",
       "      <td></td>\n",
       "      <td>K02753</td>\n",
       "      <td>pagg:AL522_01505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175271</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>PTS-Asc-EIIC, ascF; PTS system, beta-glucoside...</td>\n",
       "      <td>K02753</td>\n",
       "      <td></td>\n",
       "      <td>K02753</td>\n",
       "      <td>pagc:BEE12_21010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175272</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>PTS-Asc-EIIC, ascF; PTS system, beta-glucoside...</td>\n",
       "      <td>K02753</td>\n",
       "      <td></td>\n",
       "      <td>K02753</td>\n",
       "      <td>pstw:DSJ_25725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175273</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>PTS-Asc-EIIC, ascF; PTS system, beta-glucoside...</td>\n",
       "      <td>K02753</td>\n",
       "      <td></td>\n",
       "      <td>K02753</td>\n",
       "      <td>palh:B1H58_04550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175274</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>PTS-Asc-EIIC, ascF; PTS system, beta-glucoside...</td>\n",
       "      <td>K02753</td>\n",
       "      <td></td>\n",
       "      <td>K02753</td>\n",
       "      <td>psi:S70_17625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175275</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>PTS-Asc-EIIC, ascF; PTS system, beta-glucoside...</td>\n",
       "      <td>K02753</td>\n",
       "      <td></td>\n",
       "      <td>K02753</td>\n",
       "      <td>psx:DR96_2478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175276</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>PTS-Asc-EIIC, ascF; PTS system, beta-glucoside...</td>\n",
       "      <td>K02753</td>\n",
       "      <td></td>\n",
       "      <td>K02753</td>\n",
       "      <td>psta:BGK56_19860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175277</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>PTS-Asc-EIIC, ascF; PTS system, beta-glucoside...</td>\n",
       "      <td>K02753</td>\n",
       "      <td></td>\n",
       "      <td>K02753</td>\n",
       "      <td>vow:A9237_02875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175278</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>PTS-Asc-EIIC, ascF; PTS system, beta-glucoside...</td>\n",
       "      <td>K02753</td>\n",
       "      <td></td>\n",
       "      <td>K02753</td>\n",
       "      <td>vga:BSQ33_21375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175279</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>PTS-Asc-EIIC, ascF; PTS system, beta-glucoside...</td>\n",
       "      <td>K02753</td>\n",
       "      <td></td>\n",
       "      <td>K02753</td>\n",
       "      <td>vfm:VFMJ11_A1083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175280</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>PTS-Asc-EIIC, ascF; PTS system, beta-glucoside...</td>\n",
       "      <td>K02753</td>\n",
       "      <td></td>\n",
       "      <td>K02753</td>\n",
       "      <td>pgb:H744_1c1554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175281</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>PTS-Asc-EIIC, ascF; PTS system, beta-glucoside...</td>\n",
       "      <td>K02753</td>\n",
       "      <td></td>\n",
       "      <td>K02753</td>\n",
       "      <td>amed:B224_2650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175282</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>PTS-Asc-EIIC, ascF; PTS system, beta-glucoside...</td>\n",
       "      <td>K02753</td>\n",
       "      <td></td>\n",
       "      <td>K02753</td>\n",
       "      <td>acav:VI35_09660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175283</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>PTS-Asc-EIIC, ascF; PTS system, beta-glucoside...</td>\n",
       "      <td>K02753</td>\n",
       "      <td></td>\n",
       "      <td>K02753</td>\n",
       "      <td>sxy:BE24_11795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175284</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>PTS-Asc-EIIC, ascF; PTS system, beta-glucoside...</td>\n",
       "      <td>K02753</td>\n",
       "      <td></td>\n",
       "      <td>K02753</td>\n",
       "      <td>sxl:SXYLSMQ121_0059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175285</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>PTS-Asc-EIIC, ascF; PTS system, beta-glucoside...</td>\n",
       "      <td>K02753</td>\n",
       "      <td></td>\n",
       "      <td>K02753</td>\n",
       "      <td>sxo:SXYL_00060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175286</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>PTS-Asc-EIIC, ascF; PTS system, beta-glucoside...</td>\n",
       "      <td>K02753</td>\n",
       "      <td></td>\n",
       "      <td>K02753</td>\n",
       "      <td>seqo:SE1039_25650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175287</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>PTS-Asc-EIIC, ascF; PTS system, beta-glucoside...</td>\n",
       "      <td>K02753</td>\n",
       "      <td></td>\n",
       "      <td>K02753</td>\n",
       "      <td>sscu:CEP64_13140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175288</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>PTS-Asc-EIIC, ascF; PTS system, beta-glucoside...</td>\n",
       "      <td>K02753</td>\n",
       "      <td></td>\n",
       "      <td>K02753</td>\n",
       "      <td>wcb:AO080_01780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175289</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>PTS-Asc-EIIC, ascF; PTS system, beta-glucoside...</td>\n",
       "      <td>K02753</td>\n",
       "      <td></td>\n",
       "      <td>K02753</td>\n",
       "      <td>cbe:Cbei_0699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175290</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>PTS-Asc-EIIC, ascF; PTS system, beta-glucoside...</td>\n",
       "      <td>K02753</td>\n",
       "      <td></td>\n",
       "      <td>K02753</td>\n",
       "      <td>cbz:Cbs_0699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175291</th>\n",
       "      <td>Metabolism</td>\n",
       "      <td>Carbohydrate metabolism</td>\n",
       "      <td>Glycolysis / Gluconeogenesis [PATH:ko00010]</td>\n",
       "      <td>PTS-Asc-EIIC, ascF; PTS system, beta-glucoside...</td>\n",
       "      <td>K02753</td>\n",
       "      <td></td>\n",
       "      <td>K02753</td>\n",
       "      <td>cbei:LF65_00757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175292 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            level1                   level2  \\\n",
       "0       Metabolism  Carbohydrate metabolism   \n",
       "1       Metabolism  Carbohydrate metabolism   \n",
       "2       Metabolism  Carbohydrate metabolism   \n",
       "3       Metabolism  Carbohydrate metabolism   \n",
       "4       Metabolism  Carbohydrate metabolism   \n",
       "...            ...                      ...   \n",
       "175287  Metabolism  Carbohydrate metabolism   \n",
       "175288  Metabolism  Carbohydrate metabolism   \n",
       "175289  Metabolism  Carbohydrate metabolism   \n",
       "175290  Metabolism  Carbohydrate metabolism   \n",
       "175291  Metabolism  Carbohydrate metabolism   \n",
       "\n",
       "                                             level3  \\\n",
       "0       Glycolysis / Gluconeogenesis [PATH:ko00010]   \n",
       "1       Glycolysis / Gluconeogenesis [PATH:ko00010]   \n",
       "2       Glycolysis / Gluconeogenesis [PATH:ko00010]   \n",
       "3       Glycolysis / Gluconeogenesis [PATH:ko00010]   \n",
       "4       Glycolysis / Gluconeogenesis [PATH:ko00010]   \n",
       "...                                             ...   \n",
       "175287  Glycolysis / Gluconeogenesis [PATH:ko00010]   \n",
       "175288  Glycolysis / Gluconeogenesis [PATH:ko00010]   \n",
       "175289  Glycolysis / Gluconeogenesis [PATH:ko00010]   \n",
       "175290  Glycolysis / Gluconeogenesis [PATH:ko00010]   \n",
       "175291  Glycolysis / Gluconeogenesis [PATH:ko00010]   \n",
       "\n",
       "                                                 function      id         EC#  \\\n",
       "0                                          HK; hexokinase  K00844  EC:2.7.1.1   \n",
       "1                                          HK; hexokinase  K00844  EC:2.7.1.1   \n",
       "2                                          HK; hexokinase  K00844  EC:2.7.1.1   \n",
       "3                                          HK; hexokinase  K00844  EC:2.7.1.1   \n",
       "4                                          HK; hexokinase  K00844  EC:2.7.1.1   \n",
       "...                                                   ...     ...         ...   \n",
       "175287  PTS-Asc-EIIC, ascF; PTS system, beta-glucoside...  K02753               \n",
       "175288  PTS-Asc-EIIC, ascF; PTS system, beta-glucoside...  K02753               \n",
       "175289  PTS-Asc-EIIC, ascF; PTS system, beta-glucoside...  K02753               \n",
       "175290  PTS-Asc-EIIC, ascF; PTS system, beta-glucoside...  K02753               \n",
       "175291  PTS-Asc-EIIC, ascF; PTS system, beta-glucoside...  K02753               \n",
       "\n",
       "        KO_NUM              GENE  \n",
       "0       K00844          hsa:3101  \n",
       "1       K00844          hsa:3098  \n",
       "2       K00844          hsa:3099  \n",
       "3       K00844         hsa:80201  \n",
       "4       K00844        ptr:462298  \n",
       "...        ...               ...  \n",
       "175287  K02753  sscu:CEP64_13140  \n",
       "175288  K02753   wcb:AO080_01780  \n",
       "175289  K02753     cbe:Cbei_0699  \n",
       "175290  K02753      cbz:Cbs_0699  \n",
       "175291  K02753   cbei:LF65_00757  \n",
       "\n",
       "[175292 rows x 8 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"level3\"]==\"Glycolysis / Gluconeogenesis [PATH:ko00010]\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.merge(annotation_hierarchy, ko_map, left_on='function',right_on='GENE', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(              KO                Anno\n",
       " 0   k127_1000000     stax:MC45_12930\n",
       " 1  k127_10000013      bos:BSY19_4235\n",
       " 2  k127_10000013  maqu:Maq22A_c11310\n",
       " 3  k127_10000013     mee:CS521_12005\n",
       " 4  k127_10000013       met:M446_2163, (5038084, 2))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_csv(\"annotations/ContigsW_Annotations.txt\",sep='\\t')\n",
    "\n",
    "df.head(), df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapKOs(df):\n",
    "    df['cost_cents'] = df.apply(\n",
    "        lambda row: apply_tariff(\n",
    "            kwh=row['energy_kwh'],\n",
    "            hour=row['date_time'].hour),\n",
    "        axis=1)\n",
    "\n",
    ">>> apply_tariff_withapply(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11762, KoNum      K18200\n",
      "Gene     hsa:5066\n",
      "Name: 11762, dtype: object)\n",
      "\n",
      "K00504\n"
     ]
    }
   ],
   "source": [
    "ko_dict = {}\n",
    "for row in ko_map.iterrows():\n",
    "    if row[1].values[1] in ko_dict:\n",
    "        print(row)\n",
    "        print()\n",
    "        print(ko_dict[row[1].values[1]])\n",
    "        break\n",
    "    ko_dict[row[1].values[1]]=row[1].values[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-c7435a1a7032>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mcontigID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeneID\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mko_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mko_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Gene\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mgeneID\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'KoNum'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mkoNum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgeneID\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bin/anaconda3/lib/python3.6/site-packages/pandas/core/ops/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other, axis)\u001b[0m\n\u001b[1;32m   1227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1229\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mna_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1230\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m                 raise TypeError(\n",
      "\u001b[0;32m~/bin/anaconda3/lib/python3.6/site-packages/pandas/core/ops/__init__.py\u001b[0m in \u001b[0;36mna_op\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1089\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1091\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_comp_method_OBJECT_ARRAY\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_datetimelike_v_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bin/anaconda3/lib/python3.6/site-packages/pandas/core/ops/__init__.py\u001b[0m in \u001b[0;36m_comp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m   1067\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvec_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1069\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1070\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "annos = Annotation()\n",
    "missing = Counter()\n",
    "with open(\"annotations/MetagenomicAssemblyAnnotations_filtered_90PID.txt\",\"r\") as fh:\n",
    "    for i,line in enumerate(fh):\n",
    "        if i%500000==0:print(i,end=' ')\n",
    "        rec = line.strip().split(\"\\t\")\n",
    "        contigID, geneID = rec[0],rec[1]\n",
    "        val = ko_map.loc[ko_map[\"Gene\"] == geneID,['KoNum']]\n",
    "        try:koNum = val.values[0][0]\n",
    "        except: missing[geneID] += 1\n",
    "        annos[contigID] = koNum\n",
    "dump(annos,open(\"pickles/ContigAnnotationMap.p\",\"wb\"))\n",
    "dump(missing,open(\"pickles/NotInKO_Map.p\",\"wb\"))\n",
    "len(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "class Annotation:\n",
    "    def __init__(self):\n",
    "        self.contigs = {} # ContigsName -> set of related Annotations\n",
    "        self.annotations = {} # KO number -> contigs with that KO\n",
    "    def __setitem__(self,key,value):\n",
    "        try: self.contigs[key].append(value)\n",
    "        except: self.contigs[key] = [value]\n",
    "        try: self.annotations[value].append(key)\n",
    "        except: self.annotations[value] = [key]\n",
    "    def __getitem__(self,key): return self.contigs[key][randint(0,len(self.contigs[key]))]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating the annotation fasta files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.SeqIO import parse, write\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "annotatedRegions = open(\"assemblies/AnnotatedContigs.fa\",\"w\")\n",
    "geneDescripts = open(\"annotations/AnnotationDescripts.bed\",\"w\")\n",
    "annotations = glob(\"mags/final.contigs.*/*.gbk\")\n",
    "seqs = set()\n",
    "hypoCounter = 0\n",
    "for fname in annotations:\n",
    "    for rec in parse(fname,'genbank'):\n",
    "        for feature in rec.features:\n",
    "            try:\n",
    "                product = feature.qualifiers['product'][0]\n",
    "                #if product == \"hypothetical protein\":continue\n",
    "                #subSeq = rec.seq[feature.location.start:feature.location.end]\n",
    "                hypoCounter += int(product == \"hypothetical protein\")\n",
    "                geneDescripts.write(\"%s\\t%i\\t%i\\t%s\\n\" % (rec.id,feature.location.start,feature.location.end,product))\n",
    "                if rec.id in seqs: continue\n",
    "                rec.seq = rec.seq.upper()\n",
    "                write(rec,annotatedRegions,\"fasta\")\n",
    "                seqs.add(rec.id)\n",
    "            except:pass\n",
    "annotatedRegions.close()\n",
    "geneDescripts.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id=\"occon\">Calculate Abundance and occupancy of contigs in samples</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. G5R1_NF_09MAY2016_LD1\t2. G5R2_NF_09MAY2016_LD1\t3. G5R3_NF_09MAY2016_LD1\t\n",
      "4. G5R4_NF_09MAY2016_LD1\t5. G5R1_MAIN_09MAY2016_LD1\t6. G5R2_MAIN_09MAY2016_LD1\t\n",
      "7. G5R3_MAIN_09MAY2016_LD1\t8. G5R4_MAIN_09MAY2016_LD1\t9. G5R1_NF_31MAY2016_LD1\t\n",
      "10. G5R2_NF_31MAY2016_LD1\t11. G5R3_NF_31MAY2016_LD1\t12. G5R4_NF_31MAY2016_LD1\t\n",
      "13. G5R1_MAIN_31MAY2016_LD1\t14. G5R2_MAIN_31MAY2016_LD1\t15. G5R3_MAIN_31MAY2016_LD1\t\n",
      "16. G5R4_MAIN_31MAY2016_LD1\t17. G5R1_NF_20JUN2016_LD1\t18. G5R2_NF_20JUN2016_LD1\t\n",
      "19. G5R3_NF_20JUN2016_LD1\t20. G5R4_NF_20JUN2016_LD1\t21. G5R1_MAIN_20JUN2016_LD1\t\n",
      "22. G5R2_MAIN_20JUN2016_LD1\t23. G5R3_MAIN_20JUN2016_LD1\t24. G5R4_MAIN_20JUN2016_LD1\t\n",
      "25. G5R1_NF_12JUL2016_LD1\t26. G5R2_NF_12JUL2016_LD1\t27. G5R3_NF_12JUL2016_LD1\t\n",
      "28. G5R4_NF_12JUL2016_LD1\t29. G5R1_MAIN_12JUL2016_LD1\t30. G5R2_MAIN_12JUL2016_LD1\t\n",
      "31. G5R3_MAIN_12JUL2016_LD1\t32. G5R4_MAIN_12JUL2016_LD1\t33. G5R1_NF_01AUG2016_LD1\t\n",
      "34. G5R2_NF_01AUG2016_LD1\t35. G5R3_NF_01AUG2016_LD1\t36. G5R4_NF_01AUG2016_LD1\t\n",
      "37. G5R1_MAIN_01AUG2016_LD1\t38. G5R2_MAIN_01AUG2016_LD1\t39. G5R3_MAIN_01AUG2016_LD1\t\n",
      "40. G5R4_MAIN_01AUG2016_LD1\t41. G5R1_NF_22AUG2016_LD1\t42. G5R2_NF_22AUG2016_LD1\t\n",
      "43. G5R3_NF_22AUG2016_LD1\t44. G5R4_NF_22AUG2016_LD1\t45. G5R1_MAIN_22AUG2016_LD1\t\n",
      "46. G5R2_MAIN_22AUG2016_LD1\t47. G5R3_MAIN_22AUG2016_LD1\t48. G5R4_MAIN_22AUG2016_LD1\t\n",
      "49. G5R1_NF_12SEP2016_LD1\t50. G5R2_NF_12SEP2016_LD1\t51. G5R3_NF_12SEP2016_LD1\t\n",
      "52. G5R4_NF_12SEP2016_LD1\t53. G5R1_MAIN_12SEP2016_LD1\t54. G5R2_MAIN_12SEP2016_LD1\t\n",
      "55. G5R3_MAIN_12SEP2016_LD1\t56. G5R4_MAIN_12SEP2016_LD1\t57. G5R1_NF_03OCT2016_LD1\t\n",
      "58. G5R2_NF_03OCT2016_LD1\t59. G5R3_NF_03OCT2016_LD1\t60. G5R4_NF_03OCT2016_LD1\t\n",
      "61. G5R1_MAIN_03OCT2016_LD1\t62. G5R2_MAIN_03OCT2016_LD1\t63. G5R3_MAIN_03OCT2016_LD1\t\n",
      "64. G5R4_MAIN_03OCT2016_LD1\t65. G6R1_NF_09MAY2016_LD1\t66. G6R2_NF_09MAY2016_LD1\t\n",
      "67. G6R3_NF_09MAY2016_LD1\t68. G6R4_NF_09MAY2016_LD1\t69. G6R1_MAIN_09MAY2016_LD1\t\n",
      "70. G6R2_MAIN_09MAY2016_LD1\t71. G6R3_MAIN_09MAY2016_LD1\t72. G6R4_MAIN_09MAY2016_LD1\t\n",
      "73. G6R1_NF_31MAY2016_LD1\t74. G6R2_NF_31MAY2016_LD1\t75. G6R3_NF_31MAY2016_LD1\t\n",
      "76. G6R4_NF_31MAY2016_LD1\t77. G6R1_MAIN_31MAY2016_LD1\t78. G6R2_MAIN_31MAY2016_LD1\t\n",
      "79. G6R3_MAIN_31MAY2016_LD1\t80. G6R4_MAIN_31MAY2016_LD1\t81. G6R1_NF_20JUN2016_LD1\t\n",
      "82. G6R2_NF_20JUN2016_LD1\t83. G6R3_NF_20JUN2016_LD1\t84. G6R4_NF_20JUN2016_LD1\t\n",
      "85. G6R1_MAIN_20JUN2016_LD1\t86. G6R2_MAIN_20JUN2016_LD1\t87. G6R3_MAIN_20JUN2016_LD1\t\n",
      "88. G6R4_MAIN_20JUN2016_LD1\t89. G6R1_NF_12JUL2016_LD1\t90. G6R2_NF_12JUL2016_LD1\t\n",
      "91. G6R3_NF_12JUL2016_LD1\t92. G6R4_NF_12JUL2016_LD1\t93. G6R1_MAIN_12JUL2016_LD1\t\n",
      "94. G6R2_MAIN_12JUL2016_LD1\t95. G6R3_MAIN_12JUL2016_LD1\t96. G6R4_MAIN_12JUL2016_LD1\t\n",
      "97. G6R1_NF_01AUG2016_LD1\t98. G6R2_NF_01AUG2016_LD1\t99. G6R3_NF_01AUG2016_LD1\t\n",
      "100. G6R4_NF_01AUG2016_LD1\t101. G6R1_MAIN_01AUG2016_LD1\t102. G6R2_MAIN_01AUG2016_LD1\t\n",
      "103. G6R3_MAIN_01AUG2016_LD1\t104. G6R4_MAIN_01AUG2016_LD1\t105. G6R1_NF_22AUG2016_LD1\t\n",
      "106. G6R2_NF_22AUG2016_LD1\t107. G6R3_NF_22AUG2016_LD1\t108. G6R4_NF_22AUG2016_LD1\t\n",
      "109. G6R1_MAIN_22AUG2016_LD1\t110. G6R2_MAIN_22AUG2016_LD1\t111. G6R3_MAIN_22AUG2016_LD1\t\n",
      "112. G6R4_MAIN_22AUG2016_LD1\t113. G6R1_NF_12SEP2016_LD1\t114. G6R2_NF_12SEP2016_LD1\t\n",
      "115. G6R3_NF_12SEP2016_LD1\t116. G6R4_NF_12SEP2016_LD1\t117. G6R1_MAIN_12SEP2016_LD1\t\n",
      "118. G6R2_MAIN_12SEP2016_LD1\t119. G6R3_MAIN_12SEP2016_LD1\t120. G6R4_MAIN_12SEP2016_LD1\t\n",
      "121. G6R1_NF_03OCT2016_LD1\t122. G6R2_NF_03OCT2016_LD1\t123. G6R3_NF_03OCT2016_LD1\t\n",
      "124. G6R4_NF_03OCT2016_LD1\t125. G6R1_MAIN_03OCT2016_LD1\t126. G6R2_MAIN_03OCT2016_LD1\t\n",
      "127. G6R3_MAIN_03OCT2016_LD1\t128. G6R4_MAIN_03OCT2016_LD1\t129. G6R1_NF_07NOV2016_LD1\t\n",
      "130. G6R2_NF_07NOV2016_LD1\t131. G6R3_NF_07NOV2016_LD1\t132. G6R4_NF_07NOV2016_LD1\t\n",
      "133. G6R1_MAIN_07NOV2016_LD1\t134. G6R2_MAIN_07NOV2016_LD1\t135. G6R3_MAIN_07NOV2016_LD1\t\n",
      "136. G6R4_MAIN_07NOV2016_LD1\t"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Individual Sample\n",
    "from collections import Counter\n",
    "seqPresenceCounter, seqMappedCounter = Counter(), Counter()\n",
    "missingFiles = set()\n",
    "for i, statFName in enumerate(metadata.index):\n",
    "    print(\"%i. %s\" % (i,statFName),end = '\\t')\n",
    "    try:\n",
    "        with open(\"mapping/metaG/stats/%s.tsv\" % statFName) as fh:\n",
    "            for line in fh:\n",
    "                rec = line.strip().split()\n",
    "                seqMappedCounter[rec[0]] += int(rec[2])\n",
    "                seqPresenceCounter[rec[0]] += int(int(rec[2])>0)\n",
    "        if i % 3 == 0:print()\n",
    "    except:\n",
    "        missingFiles.add(\"mapping/metaG/stats/%s.tsv\" % statFName)\n",
    "dump(seqPresenceCounter,open(\"pickles/seqPresenceCounter_genes.p\",\"wb\"))\n",
    "dump(seqMappedCounter,  open(\"pickles/seqMappedCounter_genes.p\",  \"wb\"))  \n",
    "seqPresenceDist = Series(load(open(\"pickles/seqPresenceCounter_genes.p\",\"rb\")))/136.0\n",
    "seqPresenceDist.plot.hist();\n",
    "\n",
    "dump(missingFiles,open(\"pickles/missingFiles_genes.p\",\"wb\")) \n",
    "len(missingFiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 15988 2.32% 0 0.00%\n",
      "1 51005 7.39% 35,017 0.31%\n",
      "2 91446 13.25% 115,899 1.04%\n",
      "3 130248 18.87% 232,305 2.08%\n",
      "4 165899 24.04% 374,909 3.36%\n",
      "5 198234 28.72% 536,584 4.81%\n",
      "6 227947 33.03% 714,862 6.41%\n",
      "7 255145 36.97% 905,248 8.12%\n",
      "8 280678 40.67% 1,109,512 9.96%\n",
      "9 304674 44.14% 1,325,476 11.89%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seqPresenceCounter = load(open(\"pickles/seqPresenceCounter_genes.p\",\"rb\"))\n",
    "smp = Series(seqPresenceCounter)\n",
    "totalReads = smp.sum()\n",
    "for i in range(10):\n",
    "    sub = smp[smp <= i ]\n",
    "    subSum = sub.sum()\n",
    "    print(i,len(sub),\"%.2f%%\" % (len(sub)/len(smp)*100),comma(subSum),\"%.2f%%\" % ((subSum/totalReads)*100))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove anything that is in less than 5 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Number of genes: 690,218\n",
      "After Number of genes: 524,319\n"
     ]
    }
   ],
   "source": [
    "print(\"Before Number of genes:\",comma(len(smp)))\n",
    "keepers = set(smp[smp >= 5].index)\n",
    "print(\"After Number of genes:\",comma(len(keepers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the single copy number values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>treatment</th>\n",
       "      <th>plot_name</th>\n",
       "      <th>rep</th>\n",
       "      <th>sampling_date</th>\n",
       "      <th>Sampling Time</th>\n",
       "      <th>type</th>\n",
       "      <th>Date</th>\n",
       "      <th>JGI_File</th>\n",
       "      <th>SingleCopyCount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nucleic_acid_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>G5R1_NF_09MAY2016_LD1</th>\n",
       "      <td>nitrogen free</td>\n",
       "      <td>G5R1_NF</td>\n",
       "      <td>1</td>\n",
       "      <td>5/9/16</td>\n",
       "      <td>12:00</td>\n",
       "      <td>G5</td>\n",
       "      <td>2016-05-09</td>\n",
       "      <td>11425.5.206700.GCCTTGT-AACAAGG.fastq.gz</td>\n",
       "      <td>13.848511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G5R2_NF_09MAY2016_LD1</th>\n",
       "      <td>nitrogen free</td>\n",
       "      <td>G5R2_NF</td>\n",
       "      <td>2</td>\n",
       "      <td>5/9/16</td>\n",
       "      <td>14:43</td>\n",
       "      <td>G5</td>\n",
       "      <td>2016-05-09</td>\n",
       "      <td>11425.5.206700.CTGACAC-TGTGTCA.fastq.gz</td>\n",
       "      <td>18.376013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G5R3_NF_09MAY2016_LD1</th>\n",
       "      <td>nitrogen free</td>\n",
       "      <td>G5R3_NF</td>\n",
       "      <td>3</td>\n",
       "      <td>5/9/16</td>\n",
       "      <td>15:26</td>\n",
       "      <td>G5</td>\n",
       "      <td>2016-05-09</td>\n",
       "      <td>11425.3.206650.CCAGTGT-AACACTG.fastq.gz</td>\n",
       "      <td>18.661476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G5R4_NF_09MAY2016_LD1</th>\n",
       "      <td>nitrogen free</td>\n",
       "      <td>G5R4_NF</td>\n",
       "      <td>4</td>\n",
       "      <td>5/9/16</td>\n",
       "      <td>13:56</td>\n",
       "      <td>G5</td>\n",
       "      <td>2016-05-09</td>\n",
       "      <td>11425.5.206700.TGTACAC-GGTGTAC.fastq.gz</td>\n",
       "      <td>29.482367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G5R1_MAIN_09MAY2016_LD1</th>\n",
       "      <td>standard fertilization</td>\n",
       "      <td>G5R1_MAIN</td>\n",
       "      <td>1</td>\n",
       "      <td>5/9/16</td>\n",
       "      <td>12:00</td>\n",
       "      <td>G5</td>\n",
       "      <td>2016-05-09</td>\n",
       "      <td>11425.3.206650.GAGCTCA-TTGAGCT.fastq.gz</td>\n",
       "      <td>21.415810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      treatment  plot_name  rep sampling_date  \\\n",
       "nucleic_acid_name                                                               \n",
       "G5R1_NF_09MAY2016_LD1             nitrogen free    G5R1_NF    1        5/9/16   \n",
       "G5R2_NF_09MAY2016_LD1             nitrogen free    G5R2_NF    2        5/9/16   \n",
       "G5R3_NF_09MAY2016_LD1             nitrogen free    G5R3_NF    3        5/9/16   \n",
       "G5R4_NF_09MAY2016_LD1             nitrogen free    G5R4_NF    4        5/9/16   \n",
       "G5R1_MAIN_09MAY2016_LD1  standard fertilization  G5R1_MAIN    1        5/9/16   \n",
       "\n",
       "                        Sampling Time type       Date  \\\n",
       "nucleic_acid_name                                       \n",
       "G5R1_NF_09MAY2016_LD1           12:00   G5 2016-05-09   \n",
       "G5R2_NF_09MAY2016_LD1           14:43   G5 2016-05-09   \n",
       "G5R3_NF_09MAY2016_LD1           15:26   G5 2016-05-09   \n",
       "G5R4_NF_09MAY2016_LD1           13:56   G5 2016-05-09   \n",
       "G5R1_MAIN_09MAY2016_LD1         12:00   G5 2016-05-09   \n",
       "\n",
       "                                                        JGI_File  \\\n",
       "nucleic_acid_name                                                  \n",
       "G5R1_NF_09MAY2016_LD1    11425.5.206700.GCCTTGT-AACAAGG.fastq.gz   \n",
       "G5R2_NF_09MAY2016_LD1    11425.5.206700.CTGACAC-TGTGTCA.fastq.gz   \n",
       "G5R3_NF_09MAY2016_LD1    11425.3.206650.CCAGTGT-AACACTG.fastq.gz   \n",
       "G5R4_NF_09MAY2016_LD1    11425.5.206700.TGTACAC-GGTGTAC.fastq.gz   \n",
       "G5R1_MAIN_09MAY2016_LD1  11425.3.206650.GAGCTCA-TTGAGCT.fastq.gz   \n",
       "\n",
       "                         SingleCopyCount  \n",
       "nucleic_acid_name                         \n",
       "G5R1_NF_09MAY2016_LD1          13.848511  \n",
       "G5R2_NF_09MAY2016_LD1          18.376013  \n",
       "G5R3_NF_09MAY2016_LD1          18.661476  \n",
       "G5R4_NF_09MAY2016_LD1          29.482367  \n",
       "G5R1_MAIN_09MAY2016_LD1        21.415810  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob(\"mapping/metaG/annotatedContigs/logs/singleCopyGeneCounts/*.txt\")\n",
    "metadata[\"SingleCopyCount\"] = 0.0\n",
    "for fname in files:\n",
    "    with open(fname) as fh:\n",
    "        lines = fh.readlines()[-1].strip().split('\\t')\n",
    "        sampleName = fname[fname.rfind('/')+1:-4]\n",
    "        metadata.at[sampleName,\"SingleCopyCount\"] = float(lines[-1])\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the count numbers and normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reads: 4,269,227\n"
     ]
    }
   ],
   "source": [
    "from Bio.SeqIO import parse\n",
    "readLens={}\n",
    "for rec in parse(\"assemblies/AnnotatedContigs.fa\",\"fasta\"): readLens[rec.id] = len(rec.seq)/1000\n",
    "#RPKG = (reads mapped to gene)/(gene length in kb)/(genome equivalents)\n",
    "print(\"Number of reads: %s\" % (comma(len(readLens))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "readMap = {}\n",
    "for line in open(\"mapping/metaG/stats/G5R1_NF_09MAY2016_LD1.tsv\"):\n",
    "    rec = line.strip().split()\n",
    "    if rec[0] not in keepers:continue\n",
    "    readName = rec[0][:rec[0].rfind(\"_\")]\n",
    "    readName = readName[:readName.rfind(\"_\")]\n",
    "    readMap[rec[0]] = readName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. G5R1_NF_09MAY2016_LD1\t2. G5R2_NF_09MAY2016_LD1\t3. G5R3_NF_09MAY2016_LD1\t\n",
      "4. G5R4_NF_09MAY2016_LD1\t5. G5R1_MAIN_09MAY2016_LD1\t6. G5R2_MAIN_09MAY2016_LD1\t\n",
      "7. G5R3_MAIN_09MAY2016_LD1\t8. G5R4_MAIN_09MAY2016_LD1\t9. G5R1_NF_31MAY2016_LD1\t\n",
      "10. G5R2_NF_31MAY2016_LD1\t11. G5R3_NF_31MAY2016_LD1\t12. G5R4_NF_31MAY2016_LD1\t\n",
      "13. G5R1_MAIN_31MAY2016_LD1\t14. G5R2_MAIN_31MAY2016_LD1\t15. G5R3_MAIN_31MAY2016_LD1\t\n",
      "16. G5R4_MAIN_31MAY2016_LD1\t17. G5R1_NF_20JUN2016_LD1\t18. G5R2_NF_20JUN2016_LD1\t\n",
      "19. G5R3_NF_20JUN2016_LD1\t20. G5R4_NF_20JUN2016_LD1\t21. G5R1_MAIN_20JUN2016_LD1\t\n",
      "22. G5R2_MAIN_20JUN2016_LD1\t23. G5R3_MAIN_20JUN2016_LD1\t24. G5R4_MAIN_20JUN2016_LD1\t\n",
      "25. G5R1_NF_12JUL2016_LD1\t26. G5R2_NF_12JUL2016_LD1\t27. G5R3_NF_12JUL2016_LD1\t\n",
      "28. G5R4_NF_12JUL2016_LD1\t29. G5R1_MAIN_12JUL2016_LD1\t30. G5R2_MAIN_12JUL2016_LD1\t\n",
      "31. G5R3_MAIN_12JUL2016_LD1\t32. G5R4_MAIN_12JUL2016_LD1\t33. G5R1_NF_01AUG2016_LD1\t\n",
      "34. G5R2_NF_01AUG2016_LD1\t35. G5R3_NF_01AUG2016_LD1\t36. G5R4_NF_01AUG2016_LD1\t\n",
      "37. G5R1_MAIN_01AUG2016_LD1\t38. G5R2_MAIN_01AUG2016_LD1\t39. G5R3_MAIN_01AUG2016_LD1\t\n",
      "40. G5R4_MAIN_01AUG2016_LD1\t41. G5R1_NF_22AUG2016_LD1\t42. G5R2_NF_22AUG2016_LD1\t\n",
      "43. G5R3_NF_22AUG2016_LD1\t44. G5R4_NF_22AUG2016_LD1\t45. G5R1_MAIN_22AUG2016_LD1\t\n",
      "46. G5R2_MAIN_22AUG2016_LD1\t47. G5R3_MAIN_22AUG2016_LD1\t48. G5R4_MAIN_22AUG2016_LD1\t\n",
      "49. G5R1_NF_12SEP2016_LD1\t50. G5R2_NF_12SEP2016_LD1\t51. G5R3_NF_12SEP2016_LD1\t\n",
      "52. G5R4_NF_12SEP2016_LD1\t53. G5R1_MAIN_12SEP2016_LD1\t54. G5R2_MAIN_12SEP2016_LD1\t\n",
      "55. G5R3_MAIN_12SEP2016_LD1\t56. G5R4_MAIN_12SEP2016_LD1\t57. G5R1_NF_03OCT2016_LD1\t\n",
      "58. G5R2_NF_03OCT2016_LD1\t59. G5R3_NF_03OCT2016_LD1\t60. G5R4_NF_03OCT2016_LD1\t\n",
      "61. G5R1_MAIN_03OCT2016_LD1\t62. G5R2_MAIN_03OCT2016_LD1\t63. G5R3_MAIN_03OCT2016_LD1\t\n",
      "64. G5R4_MAIN_03OCT2016_LD1\t65. G6R1_NF_09MAY2016_LD1\t66. G6R2_NF_09MAY2016_LD1\t\n",
      "67. G6R3_NF_09MAY2016_LD1\t68. G6R4_NF_09MAY2016_LD1\t69. G6R1_MAIN_09MAY2016_LD1\t\n",
      "70. G6R2_MAIN_09MAY2016_LD1\t71. G6R3_MAIN_09MAY2016_LD1\t72. G6R4_MAIN_09MAY2016_LD1\t\n",
      "73. G6R1_NF_31MAY2016_LD1\t74. G6R2_NF_31MAY2016_LD1\t75. G6R3_NF_31MAY2016_LD1\t\n",
      "76. G6R4_NF_31MAY2016_LD1\t77. G6R1_MAIN_31MAY2016_LD1\t78. G6R2_MAIN_31MAY2016_LD1\t\n",
      "79. G6R3_MAIN_31MAY2016_LD1\t80. G6R4_MAIN_31MAY2016_LD1\t81. G6R1_NF_20JUN2016_LD1\t\n",
      "82. G6R2_NF_20JUN2016_LD1\t83. G6R3_NF_20JUN2016_LD1\t84. G6R4_NF_20JUN2016_LD1\t\n",
      "85. G6R1_MAIN_20JUN2016_LD1\t86. G6R2_MAIN_20JUN2016_LD1\t87. G6R3_MAIN_20JUN2016_LD1\t\n",
      "88. G6R4_MAIN_20JUN2016_LD1\t89. G6R1_NF_12JUL2016_LD1\t90. G6R2_NF_12JUL2016_LD1\t\n",
      "91. G6R3_NF_12JUL2016_LD1\t92. G6R4_NF_12JUL2016_LD1\t93. G6R1_MAIN_12JUL2016_LD1\t\n",
      "94. G6R2_MAIN_12JUL2016_LD1\t95. G6R3_MAIN_12JUL2016_LD1\t96. G6R4_MAIN_12JUL2016_LD1\t\n",
      "97. G6R1_NF_01AUG2016_LD1\t98. G6R2_NF_01AUG2016_LD1\t99. G6R3_NF_01AUG2016_LD1\t\n",
      "100. G6R4_NF_01AUG2016_LD1\t101. G6R1_MAIN_01AUG2016_LD1\t102. G6R2_MAIN_01AUG2016_LD1\t\n",
      "103. G6R3_MAIN_01AUG2016_LD1\t104. G6R4_MAIN_01AUG2016_LD1\t105. G6R1_NF_22AUG2016_LD1\t\n",
      "106. G6R2_NF_22AUG2016_LD1\t107. G6R3_NF_22AUG2016_LD1\t108. G6R4_NF_22AUG2016_LD1\t\n",
      "109. G6R1_MAIN_22AUG2016_LD1\t110. G6R2_MAIN_22AUG2016_LD1\t111. G6R3_MAIN_22AUG2016_LD1\t\n",
      "112. G6R4_MAIN_22AUG2016_LD1\t113. G6R1_NF_12SEP2016_LD1\t114. G6R2_NF_12SEP2016_LD1\t\n",
      "115. G6R3_NF_12SEP2016_LD1\t116. G6R4_NF_12SEP2016_LD1\t117. G6R1_MAIN_12SEP2016_LD1\t\n",
      "118. G6R2_MAIN_12SEP2016_LD1\t119. G6R3_MAIN_12SEP2016_LD1\t120. G6R4_MAIN_12SEP2016_LD1\t\n",
      "121. G6R1_NF_03OCT2016_LD1\t122. G6R2_NF_03OCT2016_LD1\t123. G6R3_NF_03OCT2016_LD1\t\n",
      "124. G6R4_NF_03OCT2016_LD1\t125. G6R1_MAIN_03OCT2016_LD1\t126. G6R2_MAIN_03OCT2016_LD1\t\n",
      "127. G6R3_MAIN_03OCT2016_LD1\t128. G6R4_MAIN_03OCT2016_LD1\t129. G6R1_NF_07NOV2016_LD1\t\n",
      "130. G6R2_NF_07NOV2016_LD1\t131. G6R3_NF_07NOV2016_LD1\t132. G6R4_NF_07NOV2016_LD1\t\n",
      "133. G6R1_MAIN_07NOV2016_LD1\t134. G6R2_MAIN_07NOV2016_LD1\t135. G6R3_MAIN_07NOV2016_LD1\t\n",
      "136. G6R4_MAIN_07NOV2016_LD1\t"
     ]
    }
   ],
   "source": [
    "allCounts,counter = {},0\n",
    "for sampleID in metadata.index:\n",
    "    counter += 1\n",
    "    print(\"%i. %s\" % (counter,sampleID),end='\\t')\n",
    "    allCounts[sampleID] = {}\n",
    "    for line in open(\"mapping/metaG/stats/%s.tsv\" % sampleID):\n",
    "        rec = line.strip().split()\n",
    "        if rec[0] not in keepers:continue\n",
    "        allCounts[sampleID][rec[0]] = float(rec[2])/readLens[readMap[rec[0]]]/metadata.at[sampleID,\"SingleCopyCount\"]\n",
    "    if counter % 3 == 0: print()\n",
    "allCounts = DataFrame(allCounts) \n",
    "dump(allCounts,open(\"pickles/allCounts_genes.p\",\"wb\"))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>G5R1_NF_09MAY2016_LD1</th>\n",
       "      <th>G5R2_NF_09MAY2016_LD1</th>\n",
       "      <th>G5R3_NF_09MAY2016_LD1</th>\n",
       "      <th>G5R4_NF_09MAY2016_LD1</th>\n",
       "      <th>G5R1_MAIN_09MAY2016_LD1</th>\n",
       "      <th>G5R2_MAIN_09MAY2016_LD1</th>\n",
       "      <th>G5R3_MAIN_09MAY2016_LD1</th>\n",
       "      <th>G5R4_MAIN_09MAY2016_LD1</th>\n",
       "      <th>G5R1_NF_31MAY2016_LD1</th>\n",
       "      <th>G5R2_NF_31MAY2016_LD1</th>\n",
       "      <th>...</th>\n",
       "      <th>G6R3_MAIN_03OCT2016_LD1</th>\n",
       "      <th>G6R4_MAIN_03OCT2016_LD1</th>\n",
       "      <th>G6R1_NF_07NOV2016_LD1</th>\n",
       "      <th>G6R2_NF_07NOV2016_LD1</th>\n",
       "      <th>G6R3_NF_07NOV2016_LD1</th>\n",
       "      <th>G6R4_NF_07NOV2016_LD1</th>\n",
       "      <th>G6R1_MAIN_07NOV2016_LD1</th>\n",
       "      <th>G6R2_MAIN_07NOV2016_LD1</th>\n",
       "      <th>G6R3_MAIN_07NOV2016_LD1</th>\n",
       "      <th>G6R4_MAIN_07NOV2016_LD1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>k127_10000137_15_1326</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034584</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009317</td>\n",
       "      <td>0.002042</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005565</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k127_10000138_297_585</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k127_10000155_200_380</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005451</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k127_10000155_386_665</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004191</td>\n",
       "      <td>0.005968</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k127_100001_75_891</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011435</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008454</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 136 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       G5R1_NF_09MAY2016_LD1  G5R2_NF_09MAY2016_LD1  \\\n",
       "k127_10000137_15_1326                    0.0                    0.0   \n",
       "k127_10000138_297_585                    0.0                    0.0   \n",
       "k127_10000155_200_380                    0.0                    0.0   \n",
       "k127_10000155_386_665                    0.0                    0.0   \n",
       "k127_100001_75_891                       0.0                    0.0   \n",
       "\n",
       "                       G5R3_NF_09MAY2016_LD1  G5R4_NF_09MAY2016_LD1  \\\n",
       "k127_10000137_15_1326                    0.0                    NaN   \n",
       "k127_10000138_297_585                    0.0                    NaN   \n",
       "k127_10000155_200_380                    0.0                    NaN   \n",
       "k127_10000155_386_665                    0.0                    NaN   \n",
       "k127_100001_75_891                       0.0                    NaN   \n",
       "\n",
       "                       G5R1_MAIN_09MAY2016_LD1  G5R2_MAIN_09MAY2016_LD1  \\\n",
       "k127_10000137_15_1326                      0.0                      0.0   \n",
       "k127_10000138_297_585                      0.0                      0.0   \n",
       "k127_10000155_200_380                      0.0                      0.0   \n",
       "k127_10000155_386_665                      0.0                      0.0   \n",
       "k127_100001_75_891                         0.0                      0.0   \n",
       "\n",
       "                       G5R3_MAIN_09MAY2016_LD1  G5R4_MAIN_09MAY2016_LD1  \\\n",
       "k127_10000137_15_1326                      NaN                      0.0   \n",
       "k127_10000138_297_585                      NaN                      0.0   \n",
       "k127_10000155_200_380                      NaN                      0.0   \n",
       "k127_10000155_386_665                      NaN                      0.0   \n",
       "k127_100001_75_891                         NaN                      0.0   \n",
       "\n",
       "                       G5R1_NF_31MAY2016_LD1  G5R2_NF_31MAY2016_LD1  ...  \\\n",
       "k127_10000137_15_1326                    0.0                    0.0  ...   \n",
       "k127_10000138_297_585                    0.0                    0.0  ...   \n",
       "k127_10000155_200_380                    0.0                    0.0  ...   \n",
       "k127_10000155_386_665                    0.0                    0.0  ...   \n",
       "k127_100001_75_891                       0.0                    0.0  ...   \n",
       "\n",
       "                       G6R3_MAIN_03OCT2016_LD1  G6R4_MAIN_03OCT2016_LD1  \\\n",
       "k127_10000137_15_1326                 0.034584                      0.0   \n",
       "k127_10000138_297_585                 0.000000                      0.0   \n",
       "k127_10000155_200_380                 0.000000                      0.0   \n",
       "k127_10000155_386_665                 0.000000                      0.0   \n",
       "k127_100001_75_891                    0.000000                      0.0   \n",
       "\n",
       "                       G6R1_NF_07NOV2016_LD1  G6R2_NF_07NOV2016_LD1  \\\n",
       "k127_10000137_15_1326               0.000000               0.009317   \n",
       "k127_10000138_297_585               0.000000               0.000000   \n",
       "k127_10000155_200_380               0.005451               0.000000   \n",
       "k127_10000155_386_665               0.000000               0.000000   \n",
       "k127_100001_75_891                  0.000000               0.000000   \n",
       "\n",
       "                       G6R3_NF_07NOV2016_LD1  G6R4_NF_07NOV2016_LD1  \\\n",
       "k127_10000137_15_1326               0.002042                    NaN   \n",
       "k127_10000138_297_585               0.000000                    NaN   \n",
       "k127_10000155_200_380               0.000000                    NaN   \n",
       "k127_10000155_386_665               0.000000                    NaN   \n",
       "k127_100001_75_891                  0.011435                    NaN   \n",
       "\n",
       "                       G6R1_MAIN_07NOV2016_LD1  G6R2_MAIN_07NOV2016_LD1  \\\n",
       "k127_10000137_15_1326                 0.005565                 0.000000   \n",
       "k127_10000138_297_585                 0.000000                 0.000000   \n",
       "k127_10000155_200_380                 0.000000                 0.000000   \n",
       "k127_10000155_386_665                 0.004191                 0.005968   \n",
       "k127_100001_75_891                    0.000000                 0.008454   \n",
       "\n",
       "                       G6R3_MAIN_07NOV2016_LD1  G6R4_MAIN_07NOV2016_LD1  \n",
       "k127_10000137_15_1326                      0.0                      NaN  \n",
       "k127_10000138_297_585                      0.0                      NaN  \n",
       "k127_10000155_200_380                      0.0                      NaN  \n",
       "k127_10000155_386_665                      0.0                      NaN  \n",
       "k127_100001_75_891                         0.0                      NaN  \n",
       "\n",
       "[5 rows x 136 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allCounts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys = [],[]\n",
    "for i in range(1,101):\n",
    "    xs.append(i)\n",
    "    ys.append(len(seqPresenceDist[seqPresenceDist >= i/100.0]))\n",
    "plt.plot(xs,ys)\n",
    "plt.xlabel('Percent of samples',fontsize=14)\n",
    "plt.ylabel('Contigs with >= 1 read',fontsize=14)\n",
    "plt.savefig(\"figures/GeneAbundance.png\",bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqPresenceCounter = Series(load(open(\"pickles/seqPresenceCounter_genes.p\",\"rb\")))\n",
    "seqMappedCounter = Series(load(open(\"pickles/seqMappedCounter_genes.p\",\"rb\")))\n",
    "seqMappedCounter.describe()\n",
    "seqPresenceCounter.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "allCounts = load(open(\"pickles/allCounts_genes.p\",\"rb\"))\n",
    "# allCounts[\"Average\"] = allCounts.sum(axis=1)/float(len(allCounts.columns))\n",
    "# allCounts[\"Average\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>G5R1_NF_09MAY2016_LD1</th>\n",
       "      <th>G5R2_NF_09MAY2016_LD1</th>\n",
       "      <th>G5R3_NF_09MAY2016_LD1</th>\n",
       "      <th>G5R4_NF_09MAY2016_LD1</th>\n",
       "      <th>G5R1_MAIN_09MAY2016_LD1</th>\n",
       "      <th>G5R2_MAIN_09MAY2016_LD1</th>\n",
       "      <th>G5R3_MAIN_09MAY2016_LD1</th>\n",
       "      <th>G5R4_MAIN_09MAY2016_LD1</th>\n",
       "      <th>G5R1_NF_31MAY2016_LD1</th>\n",
       "      <th>G5R2_NF_31MAY2016_LD1</th>\n",
       "      <th>...</th>\n",
       "      <th>G6R3_MAIN_03OCT2016_LD1</th>\n",
       "      <th>G6R4_MAIN_03OCT2016_LD1</th>\n",
       "      <th>G6R1_NF_07NOV2016_LD1</th>\n",
       "      <th>G6R2_NF_07NOV2016_LD1</th>\n",
       "      <th>G6R3_NF_07NOV2016_LD1</th>\n",
       "      <th>G6R4_NF_07NOV2016_LD1</th>\n",
       "      <th>G6R1_MAIN_07NOV2016_LD1</th>\n",
       "      <th>G6R2_MAIN_07NOV2016_LD1</th>\n",
       "      <th>G6R3_MAIN_07NOV2016_LD1</th>\n",
       "      <th>G6R4_MAIN_07NOV2016_LD1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>G5R1_NF_09MAY2016_LD1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G5R2_NF_09MAY2016_LD1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G5R3_NF_09MAY2016_LD1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G5R4_NF_09MAY2016_LD1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G5R1_MAIN_09MAY2016_LD1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 136 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         G5R1_NF_09MAY2016_LD1  G5R2_NF_09MAY2016_LD1  \\\n",
       "G5R1_NF_09MAY2016_LD1                      NaN                    NaN   \n",
       "G5R2_NF_09MAY2016_LD1                      NaN                    NaN   \n",
       "G5R3_NF_09MAY2016_LD1                      NaN                    NaN   \n",
       "G5R4_NF_09MAY2016_LD1                      NaN                    NaN   \n",
       "G5R1_MAIN_09MAY2016_LD1                    NaN                    NaN   \n",
       "\n",
       "                         G5R3_NF_09MAY2016_LD1  G5R4_NF_09MAY2016_LD1  \\\n",
       "G5R1_NF_09MAY2016_LD1                      NaN                    NaN   \n",
       "G5R2_NF_09MAY2016_LD1                      NaN                    NaN   \n",
       "G5R3_NF_09MAY2016_LD1                      NaN                    NaN   \n",
       "G5R4_NF_09MAY2016_LD1                      NaN                    NaN   \n",
       "G5R1_MAIN_09MAY2016_LD1                    NaN                    NaN   \n",
       "\n",
       "                         G5R1_MAIN_09MAY2016_LD1  G5R2_MAIN_09MAY2016_LD1  \\\n",
       "G5R1_NF_09MAY2016_LD1                        NaN                      NaN   \n",
       "G5R2_NF_09MAY2016_LD1                        NaN                      NaN   \n",
       "G5R3_NF_09MAY2016_LD1                        NaN                      NaN   \n",
       "G5R4_NF_09MAY2016_LD1                        NaN                      NaN   \n",
       "G5R1_MAIN_09MAY2016_LD1                      NaN                      NaN   \n",
       "\n",
       "                         G5R3_MAIN_09MAY2016_LD1  G5R4_MAIN_09MAY2016_LD1  \\\n",
       "G5R1_NF_09MAY2016_LD1                        NaN                      NaN   \n",
       "G5R2_NF_09MAY2016_LD1                        NaN                      NaN   \n",
       "G5R3_NF_09MAY2016_LD1                        NaN                      NaN   \n",
       "G5R4_NF_09MAY2016_LD1                        NaN                      NaN   \n",
       "G5R1_MAIN_09MAY2016_LD1                      NaN                      NaN   \n",
       "\n",
       "                         G5R1_NF_31MAY2016_LD1  G5R2_NF_31MAY2016_LD1  ...  \\\n",
       "G5R1_NF_09MAY2016_LD1                      NaN                    NaN  ...   \n",
       "G5R2_NF_09MAY2016_LD1                      NaN                    NaN  ...   \n",
       "G5R3_NF_09MAY2016_LD1                      NaN                    NaN  ...   \n",
       "G5R4_NF_09MAY2016_LD1                      NaN                    NaN  ...   \n",
       "G5R1_MAIN_09MAY2016_LD1                    NaN                    NaN  ...   \n",
       "\n",
       "                         G6R3_MAIN_03OCT2016_LD1  G6R4_MAIN_03OCT2016_LD1  \\\n",
       "G5R1_NF_09MAY2016_LD1                        NaN                      NaN   \n",
       "G5R2_NF_09MAY2016_LD1                        NaN                      NaN   \n",
       "G5R3_NF_09MAY2016_LD1                        NaN                      NaN   \n",
       "G5R4_NF_09MAY2016_LD1                        NaN                      NaN   \n",
       "G5R1_MAIN_09MAY2016_LD1                      NaN                      NaN   \n",
       "\n",
       "                         G6R1_NF_07NOV2016_LD1  G6R2_NF_07NOV2016_LD1  \\\n",
       "G5R1_NF_09MAY2016_LD1                      NaN                    NaN   \n",
       "G5R2_NF_09MAY2016_LD1                      NaN                    NaN   \n",
       "G5R3_NF_09MAY2016_LD1                      NaN                    NaN   \n",
       "G5R4_NF_09MAY2016_LD1                      NaN                    NaN   \n",
       "G5R1_MAIN_09MAY2016_LD1                    NaN                    NaN   \n",
       "\n",
       "                         G6R3_NF_07NOV2016_LD1  G6R4_NF_07NOV2016_LD1  \\\n",
       "G5R1_NF_09MAY2016_LD1                      NaN                    NaN   \n",
       "G5R2_NF_09MAY2016_LD1                      NaN                    NaN   \n",
       "G5R3_NF_09MAY2016_LD1                      NaN                    NaN   \n",
       "G5R4_NF_09MAY2016_LD1                      NaN                    NaN   \n",
       "G5R1_MAIN_09MAY2016_LD1                    NaN                    NaN   \n",
       "\n",
       "                         G6R1_MAIN_07NOV2016_LD1  G6R2_MAIN_07NOV2016_LD1  \\\n",
       "G5R1_NF_09MAY2016_LD1                        NaN                      NaN   \n",
       "G5R2_NF_09MAY2016_LD1                        NaN                      NaN   \n",
       "G5R3_NF_09MAY2016_LD1                        NaN                      NaN   \n",
       "G5R4_NF_09MAY2016_LD1                        NaN                      NaN   \n",
       "G5R1_MAIN_09MAY2016_LD1                      NaN                      NaN   \n",
       "\n",
       "                         G6R3_MAIN_07NOV2016_LD1  G6R4_MAIN_07NOV2016_LD1  \n",
       "G5R1_NF_09MAY2016_LD1                        NaN                      NaN  \n",
       "G5R2_NF_09MAY2016_LD1                        NaN                      NaN  \n",
       "G5R3_NF_09MAY2016_LD1                        NaN                      NaN  \n",
       "G5R4_NF_09MAY2016_LD1                        NaN                      NaN  \n",
       "G5R1_MAIN_09MAY2016_LD1                      NaN                      NaN  \n",
       "\n",
       "[5 rows x 136 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allCounts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Before Filtering:\",len(allCounts))\n",
    "allCounts = allCounts[allCounts[\"Average\"]>1]\n",
    "xs,ys=[],[]\n",
    "for i in range(1,30):\n",
    "    xs.append(i)\n",
    "    ys.append(len(allCounts[allCounts[\"Average\"] > i]))\n",
    "    xs.append(i+.5)\n",
    "    ys.append(len(allCounts[allCounts[\"Average\"] > i+.5]))\n",
    "    \n",
    "allCounts.drop(\"Average\",axis=1,inplace=True)\n",
    "print(\"After Filtering:\",len(allCounts))\n",
    "#allCounts = allCounts.transpose()\n",
    "#allCounts= DataFrame(allCounts,index=allCounts.index)\n",
    "dump(allCounts,open(\"pickles/allCountsFiltered_genes.p\",\"wb\")) \n",
    "plt.plot(xs,ys)\n",
    "# plt.xlabel('Percent of samples',fontsize=14)\n",
    "# plt.ylabel('Read Count',fontsize=14)\n",
    "plt.savefig(\"figures/GeneAvgCount.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortedmeta = metadata[[\"sampling_date\",\"Date\",\"type\",\"nucleic_acid_name\",\"treatment\"]]\n",
    "sortedmeta = sortedmeta.sort_values(by=[\"type\",\"Date\"])\n",
    "counter = 0\n",
    "sampleOrder = {}  \n",
    "for id in sortedmeta.nucleic_acid_name:\n",
    "    counter+=1\n",
    "    sampleOrder[id] = counter\n",
    "\n",
    "allCounts = DataFrame(allCounts).transpose()\n",
    "allCounts['Rank'] = allCounts.index.to_series().map(sampleOrder)\n",
    "allCounts.sort_values('Rank',inplace = True)\n",
    "allCounts.drop('Rank', 1, inplace = True)\n",
    "dump(allCounts,open(\"pickles/allCountsFilteredSorted_genes.p\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allCounts = load(open(\"pickles/allCountsFilteredSorted_genes.p\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#allCounts = DataFrame(combined_abundance)\n",
    "seed = np.random.RandomState(seed=3)\n",
    "allCounts_matrix = allCounts.as_matrix()\n",
    "print(\"Calculating Distance\")\n",
    "similarities = euclidean_distances(allCounts_matrix)\n",
    "\n",
    "nsamples = len(allCounts)\n",
    "print(\"Running NMDS with %i samples\" % (nsamples))\n",
    "mds = manifold.MDS(n_components=2, max_iter=3000, eps=1e-9, random_state=seed, dissimilarity=\"precomputed\", n_jobs=1)\n",
    "pos = mds.fit(similarities).embedding_\n",
    "nmds = manifold.MDS(n_components=2, metric=False, max_iter=3000, eps=1e-12, dissimilarity=\"precomputed\", random_state=seed, n_jobs=1, n_init=1)\n",
    "npos = nmds.fit_transform(similarities, init=pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "fig = plt.figure(1)\n",
    "ax = plt.axes([0., 0., 1.5, 1.95])\n",
    "s = 100\n",
    "index = 0\n",
    "totalGroups = nsamples/4\n",
    "l1s, l2s = [], []\n",
    "dateColors = []\n",
    "for sample in sortedmeta.index:\n",
    "#     print(sample)\n",
    "    if sortedmeta[sortedmeta.index == sample].type[0] == \"G5\": \n",
    "        species = \"SG\"\n",
    "        if sortedmeta[sortedmeta.index == sample].treatment[0] == \"nitrogen free\": \n",
    "            treatment = \"NF\"\n",
    "            marker = '^'\n",
    "        else: \n",
    "            treatment = \"Fert\"\n",
    "            marker= \"v\"\n",
    "    else: \n",
    "        species = \"MC\"; \n",
    "        if sortedmeta[sortedmeta.index == sample].treatment[0] == \"nitrogen free\": \n",
    "            treatment = \"NF\"\n",
    "            marker = 'p'\n",
    "        else: \n",
    "            treatment = \"Fert\"\n",
    "            marker= \"s\"\n",
    "    lbl = \"%s_%s\" % (species,treatment)\n",
    "    date=sortedmeta[sortedmeta.index == sample].Date[0]\n",
    "    dateColors.append(scolor(index,72,species == \"SG\"))\n",
    "    plt.scatter(npos[index:index+1, 0], npos[index:index+1, 1], color=scolor(index,72,species == \"SG\"), s=s, lw=0,label=None,cmap='viridis',marker=marker)\n",
    "    index += 1\n",
    "\n",
    "for crop,marker in [['Switchgrass Unfertilized','^'],['Switchgrass Fertilized','v'],['Miscanthus Unfertilized','p'],['Miscanthus Fertilized','s'],]:\n",
    "    midval = 63/2\n",
    "    if \"Switchgrass\" not in crop: midval = 72 + 72/2\n",
    "    print(crop, scolor(midval,72, \"SG\" in crop))\n",
    "    plt.scatter([], [], c=scolor(midval,72, \"Switchgrass\" in crop), label=crop, marker=marker)\n",
    "plt.legend(scatterpoints=1, frameon=True, labelspacing=1, title='')\n",
    "#handles, labels = ax.get_legend_handles_labels()\n",
    "# plt.axis(aspect='equal')\n",
    "#cmap = mpl.colors.ListedColormap(dateColors)\n",
    "#cb1 = mpl.colorbar.ColorbarBase(ax, cmap=cmap, orientation='vertical')\n",
    "#cb1.set_label('Some Units')\n",
    "#psm = ax.pcolormesh(data, cmap=cmap, rasterized=True, vmin=-4, vmax=4)\n",
    "#fig.colorbar(cmap, ax=ax)\n",
    "#plt.colorbar(cmap, label='Time')\n",
    "# plt.clim(3, 7)\n",
    "# sort both labels and handles by labels\n",
    "# labels, handles = zip(*sorted(zip(labels, handles), key=lambda t: t[0]))\n",
    "# ax.legend(handles, labels)\n",
    "#plt.legend(handles, labels,scatterpoints=1, loc='best', shadow=False)\n",
    "plt.title(\"Switchgrass and Miscanthus Fertilized & Unfertilized NMDS\")\n",
    "# # plt.tight_layout()\n",
    "plt.savefig(\"figures/AllCombinedNMDS_genes.png\",bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allCounts = allCounts.transpose()\n",
    "allCounts.to_csv(\"stats/filteredCountTable.tsv\",sep='\\t')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "viridis = cm.get_cmap('viridis', 256)\n",
    "newcolors = viridis(np.linspace(0, 1, 256))\n",
    "pink = np.array([248/256, 24/256, 148/256, 1])\n",
    "newcolors[:25, :] = pink\n",
    "newcmp = ListedColormap(newcolors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annoMap = {}\n",
    "revMap = {}\n",
    "for line in open(\"annotations/annotationDescripts.tsv\"):\n",
    "    contID, function = line.strip().split(\"\\t\")\n",
    "#     if contID in annoMap:\n",
    "#         print(contID,function,annoMap[contID])\n",
    "#         break\n",
    "    annoMap[contID]= function\n",
    "    try:revMap[function].add(contID)\n",
    "    except:revMap[function] = set([contID])\n",
    "dist = {}\n",
    "for function,contigs in revMap.items():\n",
    "    dist[function]=len(contigs)\n",
    "dist = Series(dist)\n",
    "dist.plot.hist();\n",
    "dump(revMap,open(\"pickles/functionMap.p\",\"wb\"))\n",
    "dump(annoMap,open(\"pickles/annoMap.p\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist[dist>900]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allCounts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revMap = load(open(\"pickles/functionMap.p\",\"rb\"))\n",
    "list(revMap.keys())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import load,dump\n",
    "allCounts = load(open(\"pickles/allCounts_genes.p\",\"rb\"))\n",
    "annoMap = load(open(\"pickles/annoMap.p\",\"rb\"))\n",
    "revMap = load(open(\"pickles/functionMap.p\",\"rb\"))\n",
    "\n",
    "excCounter = 0\n",
    "geneCounts = {}\n",
    "for index,sample in enumerate(allCounts.columns):\n",
    "    geneCounts[sample]={}\n",
    "    sampleCounts = allCounts[sample]\n",
    "    print(\"%i. %s\" % (index+1,sample))\n",
    "    for function,contigs in revMap.items():\n",
    "        functCounts = sampleCounts[sampleCounts.index.isin(contigs)]\n",
    "        nReads = float(functCounts.sum(axis = 0))\n",
    "        geneCounts[sample][function] = nReads\n",
    "#         try: geneCounts[sample][function] = nReads/len(functCounts)\n",
    "#         except:\n",
    "#             excCounter +=1\n",
    "#             geneCounts[sample][function] = 0.0\n",
    "dump(geneCounts,open(\"pickles/pooledGeneCounts.p\",\"wb\"))\n",
    "print(\"There were %i genes with no representative contigs\" % (excCounter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geneCounts = DataFrame(load(open(\"pickles/pooledGeneCounts.p\",\"rb\")))\n",
    "print(len(geneCounts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geneCounts.to_csv(\"tables/GeneCounts.tsv\",sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame(geneCounts)\n",
    "remove = set()\n",
    "\n",
    "for function in df.index:\n",
    "    functionCount = float(df[df.index == function].sum(axis=1)) \n",
    "    if(functionCount == 0.0): remove.add(function)\n",
    "print(len(remove))\n",
    "df.drop(remove,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distlist = []\n",
    "for function in df.index:distlist.append(float(df[df.index == function].sum(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = Series(distlist)\n",
    "dist = dist[dist < dist.mean()*.001*dist.std()]\n",
    "dist.plot.hist()\n",
    "dist.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diamondAnnos = {}\n",
    "for line in open(\"KEGG_tools_out/diamondAnnotations_0_KOtable.txt\"):\n",
    "    rec = line.split(\"\\t\")\n",
    "    try: diamondAnnos[rec[0]].add(rec[2])\n",
    "    except:  diamondAnnos[rec[0]] = set([rec[2]])\n",
    "print(len(diamondAnnos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist,conts = [],[]\n",
    "for contID, KOList in diamondAnnos.items(): conts.append(contID); dist.append(len(KOList))\n",
    "dist = Series(dist,index=conts)\n",
    "dist.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dist[dist>=2])/float(len(dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allCounts = load(open(\"pickles/allCounts_genes.p\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medianReplicateGeneCounts = {}\n",
    "for crop in set(metadata.type):\n",
    "    for date in set(metadata.sampling_date):\n",
    "        for treatment in set(metadata.treatment):\n",
    "            replicateSamples = metadata.loc[(metadata.sampling_date==date) & (metadata.treatment==treatment) & (metadata.type == crop)]\n",
    "            if len(replicateSamples) == 0: continue\n",
    "#             print(crop,date,treatment)\n",
    "            replicateCounts = geneCounts[list(replicateSamples.nucleic_acid_name)]\n",
    "            groupID = list(replicateSamples.nucleic_acid_name)[1].replace(\"R1\",\"\").replace(\"R2\",\"\").replace(\"R3\",\"\").replace(\"R4\",\"\")\n",
    "            medianReplicateGeneCounts[groupID] = replicateCounts.median(axis=1)\n",
    "            #             \n",
    "#             sampleGroup[groupID] = {}\n",
    "#             for function, contigList in revMap.items():\n",
    "#                 functionCounts = sampleCounts[sampleCounts.index.isin(contigList)]\n",
    "#                 sampleGroup[groupID][function] = functionCounts.sum().median()\n",
    "medianReplicateGeneCounts = DataFrame(medianReplicateGeneCounts)\n",
    "medianReplicateGeneCounts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove = set()\n",
    "for function in medianReplicateGeneCounts.index:\n",
    "    if medianReplicateGeneCounts[medianReplicateGeneCounts.index == function].sum(axis=1).sum()== 0:remove.add(function)\n",
    "len(remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(medianReplicateGeneCounts.shape)\n",
    "medianReplicateGeneCounts.drop(remove,inplace=True)\n",
    "print(medianReplicateGeneCounts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(sampleGroup,open(\"pickles/deepFunctionReplicateCounts.p\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medianReplicateGeneCounts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates=metadata[[\"sampling_date\",\"Date\",\"nucleic_acid_name\"]]\n",
    "dates=dates.sort_values(by=\"Date\")\n",
    "dates=dates[[\"sampling_date\",\"nucleic_acid_name\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = metadata.sort_values(by=\"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.treatment.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persistent = set()\n",
    "crop =\"G5\"\n",
    "treatment = 'standard fertilization'\n",
    "prevTimePoint = []\n",
    "seenGenes =set()\n",
    "for crop in metadata.type.unique():\n",
    "    for treatment in metadata.treatment.unique():\n",
    "        for date in dates.sampling_date.unique():\n",
    "            replicateSamples = metadata.loc[(metadata.sampling_date==date) & (metadata.treatment==treatment) & (metadata.type == crop)]\n",
    "            if len(replicateSamples) == 0: continue\n",
    "            groupID = list(replicateSamples.nucleic_acid_name)[1].replace(\"R1\",\"\").replace(\"R2\",\"\").replace(\"R3\",\"\").replace(\"R4\",\"\")\n",
    "            if len(prevTimePoint) == 0:\n",
    "                prevTimePoint = medianReplicateGeneCounts[groupID]\n",
    "                prevTimePoint = prevTimePoint[prevTimePoint>0]\n",
    "                persistent = set(prevTimePoint.index)\n",
    "        #         print(\"There are %i genes present at start %s\" % (len(prevTimePoint),str(date)))\n",
    "                continue\n",
    "            curTimePoint = medianReplicateGeneCounts[groupID]\n",
    "            curTimePoint = curTimePoint[curTimePoint>0]\n",
    "        #     print(\"At the next time point %s there are %i genes\"%(str(date),len(curTimePoint)))\n",
    "        #     print(\"\\t%i genes existed in the last timepoint\" % (len(set(curTimePoint.index).intersection(prevTimePoint.index))))\n",
    "        #     print(\"\\t%i genes are new\" % (len(set(curTimePoint.index).difference(prevTimePoint.index))))\n",
    "            seenGenes = seenGenes.union(set(curTimePoint.index).union(prevTimePoint.index))\n",
    "        #     print(\"\\t%i genes so far\\n\" % (len(seenGenes)))\n",
    "            persistent = persistent.intersection(curTimePoint.index)\n",
    "            prevTimePoint = curTimePoint\n",
    "        print(\"There are %i genes that persist over time for %s with %s\" % (len(persistent),crop,treatment))\n",
    "        persIncreasing = persistent\n",
    "        persDecreasing = persistent\n",
    "        prevTimePoint = []\n",
    "        seenGenes =set()\n",
    "        for i,date in enumerate(dates.sampling_date.unique()):\n",
    "            replicateSamples = metadata.loc[(metadata.sampling_date==date) & (metadata.treatment==treatment) & (metadata.type == crop)]\n",
    "            if len(replicateSamples) == 0: continue\n",
    "            groupID = list(replicateSamples.nucleic_acid_name)[1].replace(\"R1\",\"\").replace(\"R2\",\"\").replace(\"R3\",\"\").replace(\"R4\",\"\")\n",
    "            if len(prevTimePoint) == 0:\n",
    "                prevTimePoint = medianReplicateGeneCounts[groupID]\n",
    "                prevTimePointDec = prevTimePoint[prevTimePoint.index.isin(persistent)]\n",
    "                prevTimePointInc = prevTimePoint[prevTimePoint.index.isin(persistent)]\n",
    "                continue\n",
    "            prevTimePointInc = prevTimePointInc[prevTimePointInc.index.isin(persIncreasing)]\n",
    "            prevTimePointDec = prevTimePointDec[prevTimePointDec.index.isin(persDecreasing)]\n",
    "            curTimePoint = medianReplicateGeneCounts[groupID]\n",
    "            curIncreasing = curTimePoint[curTimePoint.index.isin(persIncreasing)]\n",
    "            curDecreasing = curTimePoint[curTimePoint.index.isin(persDecreasing)]\n",
    "            increasing = curIncreasing[curIncreasing >= prevTimePointInc]\n",
    "            decreasing = curDecreasing[curDecreasing <= prevTimePointDec]\n",
    "            persIncreasing = set(increasing.index)\n",
    "            persDecreasing = set(decreasing.index)\n",
    "            print(\"\\tAt time %s \\t %i genes are still increasing\\t\" % (str(date), len(persIncreasing)),end='\\t')\n",
    "            print(\"%i genes are still decreasing\" % ( len(persDecreasing)))\n",
    "            \n",
    "            #Add normalization by number of reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,date in enumerate(dates.sampling_date.unique()):print(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persistent = set()\n",
    "crop =\"G6\"\n",
    "prevTimePoint = []\n",
    "seenGenes =set()\n",
    "for date in dates.sampling_date.unique():\n",
    "    replicateSamples = metadata.loc[(metadata.sampling_date==date) & (metadata.treatment==treatment) & (metadata.type == crop)]\n",
    "    if len(replicateSamples) == 0: continue\n",
    "    groupID = list(replicateSamples.nucleic_acid_name)[1].replace(\"R1\",\"\").replace(\"R2\",\"\").replace(\"R3\",\"\").replace(\"R4\",\"\")\n",
    "    if len(prevTimePoint) == 0:\n",
    "        prevTimePoint = medianReplicateGeneCounts[groupID]\n",
    "        prevTimePoint = prevTimePoint[prevTimePoint>0]\n",
    "        persistent = set(prevTimePoint.index)\n",
    "        print(\"There are %i genes present at start %s\" % (len(prevTimePoint),str(date)))\n",
    "        continue\n",
    "    curTimePoint = medianReplicateGeneCounts[groupID]\n",
    "    curTimePoint = curTimePoint[curTimePoint>0]\n",
    "    print(\"At the next time point %s there are %i genes\"%(str(date),len(curTimePoint)))\n",
    "    print(\"\\t%i genes existed in the last timepoint\" % (len(set(curTimePoint.index).intersection(prevTimePoint.index))))\n",
    "    print(\"\\t%i genes are new\" % (len(set(curTimePoint.index).difference(prevTimePoint.index))))\n",
    "    seenGenes = seenGenes.union(set(curTimePoint.index).union(prevTimePoint.index))\n",
    "    print(\"\\t%i genes so far\\n\" % (len(seenGenes)))\n",
    "    persistent = persistent.intersection(curTimePoint.index)\n",
    "    prevTimePoint = curTimePoint\n",
    "print(\"There are %i genes that persist over time\" % (len(persistent)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What genes consistently go up over time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persIncreasing = persistent\n",
    "persDecreasing = persistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# persistent\n",
    "persIncreasing = persistent\n",
    "persDecreasing = persistent\n",
    "prevTimePoint = []\n",
    "seenGenes =set()\n",
    "print(crop,treatment)\n",
    "for i,date in enumerate(dates.sampling_date.unique()):\n",
    "    replicateSamples = metadata.loc[(metadata.sampling_date==date) & (metadata.treatment==treatment) & (metadata.type == crop)]\n",
    "    if len(replicateSamples) == 0: continue\n",
    "    groupID = list(replicateSamples.nucleic_acid_name)[1].replace(\"R1\",\"\").replace(\"R2\",\"\").replace(\"R3\",\"\").replace(\"R4\",\"\")\n",
    "#     print(groupID)\n",
    "    if len(prevTimePoint) == 0:\n",
    "        prevTimePoint = medianReplicateGeneCounts[groupID]\n",
    "        prevTimePointDec = prevTimePoint[prevTimePoint.index.isin(persistent)]\n",
    "        prevTimePointInc = prevTimePoint[prevTimePoint.index.isin(persistent)]\n",
    "        continue\n",
    "    \n",
    "    prevTimePointInc = prevTimePointInc[prevTimePointInc.index.isin(persIncreasing)]\n",
    "    prevTimePointDec = prevTimePointDec[prevTimePointDec.index.isin(persDecreasing)]\n",
    "    curTimePoint = medianReplicateGeneCounts[groupID]\n",
    "    curIncreasing = curTimePoint[curTimePoint.index.isin(persIncreasing)]\n",
    "    curDecreasing = curTimePoint[curTimePoint.index.isin(persDecreasing)]\n",
    "    increasing = curIncreasing[curIncreasing >= prevTimePointInc]\n",
    "    decreasing = curDecreasing[curDecreasing <= prevTimePointDec]\n",
    "    persIncreasing = set(increasing.index)\n",
    "    persDecreasing = set(decreasing.index)\n",
    "    print(\"At time %i - %i genes are still increasing\" % (i, len(persIncreasing)),end='\\t')\n",
    "    print(\"At time %i - %i genes are still decreasing\" % (i, len(persDecreasing)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persIncreasing = persistent\n",
    "persDecreasing = persistent\n",
    "prevTimePoint = []\n",
    "seenGenes =set()\n",
    "print(crop,treatment)\n",
    "for i,date in enumerate(dates.sampling_date.unique()):\n",
    "    replicateSamples = metadata.loc[(metadata.sampling_date==date) & (metadata.treatment==treatment) & (metadata.type == crop)]\n",
    "    if len(replicateSamples) == 0: continue\n",
    "    groupID = list(replicateSamples.nucleic_acid_name)[1].replace(\"R1\",\"\").replace(\"R2\",\"\").replace(\"R3\",\"\").replace(\"R4\",\"\")\n",
    "#     print(groupID)\n",
    "    if len(prevTimePoint) == 0:\n",
    "        prevTimePoint = medianReplicateGeneCounts[groupID]\n",
    "        prevTimePointDec = prevTimePoint[prevTimePoint.index.isin(persistent)]\n",
    "        prevTimePointInc = prevTimePoint[prevTimePoint.index.isin(persistent)]\n",
    "        continue\n",
    "    \n",
    "    prevTimePointInc = prevTimePointInc[prevTimePointInc.index.isin(persIncreasing)]\n",
    "    prevTimePointDec = prevTimePointDec[prevTimePointDec.index.isin(persDecreasing)]\n",
    "    curTimePoint = medianReplicateGeneCounts[groupID]\n",
    "    curIncreasing = curTimePoint[curTimePoint.index.isin(persIncreasing)]\n",
    "    curDecreasing = curTimePoint[curTimePoint.index.isin(persDecreasing)]\n",
    "    increasing = curIncreasing[curIncreasing >= prevTimePointInc]\n",
    "    decreasing = curDecreasing[curDecreasing <= prevTimePointDec]\n",
    "    persIncreasing = set(increasing.index)\n",
    "    persDecreasing = set(decreasing.index)\n",
    "    print(\"At time %i - %i genes are still increasing\" % (i, len(persIncreasing)),end='\\t')\n",
    "    print(\"At time %i - %i genes are still decreasing\" % (i, len(persDecreasing)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTime = medianReplicateGeneCounts['G5_NF_09MAY2016_LD1']\n",
    "startTime = startTime[startTime > 0]\n",
    "print(len(startTime))\n",
    "startTime.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curTimePoint[curTimePoint.index.isin(persDecreasing)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqMappedDist = Series(load(open(\"pickles/seqMappedCounter.p\",\"rb\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "presenceDist=presenceDist/float(numSamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fh = open(\"assemblies/parts/final.contigs.%i.fa\" % (index),\"w\")\n",
    "from Bio.SeqIO import parse, write\n",
    "counter,index = 0, 0\n",
    "for rec in parse(\"assemblies/final.contigs.fa\",\"fasta\"): \n",
    "    if counter % 500000 == 0:\n",
    "        #fh.close()\n",
    "        index += 1\n",
    "        print(index,end=\" \")\n",
    "        #fh = open(\"assemblies/parts/final.contigs.%i.fa\" % (index),\"w\")\n",
    "    #write(rec,fh,\"fasta\")\n",
    "    counter+=1\n",
    "#fh.close()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#ls -laht pickles\n",
    "#head stats/11425.5.206700.GCCTTGT-AACAAGG.fastq.gz.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the dictionary for the counts\n",
    "seqCounter = {} #load(open(\"pickles/seqCounter.p\",\"rb\"))\n",
    "combined_abundance = seqCounter.copy()\n",
    "for crop in set(metadata.type):\n",
    "    for date in set(metadata.sampling_date):\n",
    "        for treatment in set(metadata.treatment):\n",
    "            sampleGroupMeta = metadata.loc[(metadata.sampling_date==date) & (metadata.treatment==treatment) & (metadata.type == crop)]\n",
    "            if len(sampleGroupMeta) == 0: continue\n",
    "            sampleAbundance = seqCounter.copy()\n",
    "            samplePresence = seqCounter.copy()\n",
    "            comFileName = \"stats/combined/%s_%s.tsv\" % (sampleGroupMeta.plot_name.unique()[0],date.replace(\"/\",\"_\"))\n",
    "            print(comFileName)\n",
    "            outfile = open(comFileName, \"w\")\n",
    "            nfiles = 4\n",
    "            for fstaName in sampleGroupMeta.index:\n",
    "                try:\n",
    "                    with open(\"stats/%s.tsv\" % (fstaName)) as fh:\n",
    "                        for line in fh:\n",
    "                            rec = line.strip().split()\n",
    "                            sampleAbundance[rec[0]] += int(rec[2])\n",
    "                            samplePresence[rec[0]]  += int(int(rec[2])>0)\n",
    "                except:\n",
    "                    print(\"\\t\\t\",comFileName,\"is missing file:\",fstaName)\n",
    "                    missingStats.append(fstaName)\n",
    "                    nfiles-=1\n",
    "                    \n",
    "            contigCounter = 0\n",
    "            for contName,presCount in samplePresence.items():\n",
    "                contigCounter += int(presCount >= 2)\n",
    "                outfile.write(\"%s\\t%s\\n\" % (contName,int(sampleAbundance[contName]/nfiles)))\n",
    "                combined_abundance[contName] += int(sampleAbundance[contName]/nfiles)\n",
    "            print(\"\\t\",contigCounter,\"Contigs Present\")\n",
    "            outfile.close()\n",
    "dump(combined_abundance,open(\"pickles/combined_abundance.p\",\"wb\"))\n",
    "dump(missingStats,open(\"pickles/missingStats.p\",\"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><a id=\"pltao\">Plot abundance and occupancy</a></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that the files are combined, let's look at p/a and abundance\n",
    "fileNames = glob(\"stats/combined/*.tsv\")\n",
    "presAbs,abundance = {},{}\n",
    "for fname in fileNames:\n",
    "    print(fname)\n",
    "    for line in open(fname): \n",
    "        rec = line.strip().split()\n",
    "        try:presAbs[rec[0]] += int(int(rec[1]) > 0)\n",
    "        except:presAbs[rec[0]] = int(int(rec[1]) > 0)\n",
    "        try:abundance[rec[0]] += int(rec[1])\n",
    "        except:abundance[rec[0]] = int(rec[1])\n",
    "\n",
    "dump(presAbs,open(\"presence_absence_combined.p\",\"wb\"))    \n",
    "dump(abundance,open(\"abundance_combined.p\",\"wb\"))   \n",
    "dist_pres = []\n",
    "numSamples = float(len(fileNames))\n",
    "for contig, count in presAbs.items(): dist_pres.append(count/float(numSamples))\n",
    "plotter = Series(dist_pres)\n",
    "plotter.plot.hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><a id=\"pltao\">Abundance</a></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combinedFiles = glob(\"stats/combined/filtered/*.tsv\")\n",
    "# presAbs = load(open(\"pickles/presence_absence_combined.p\",\"rb\"))    \n",
    "# abundance = load(open(\"pickles/abundance_combined.p\",\"rb\"))   \n",
    "# dist_pres = []\n",
    "# numSamples = float(len(combinedFiles))\n",
    "# for contig, count in presAbs.items(): dist_pres.append(count/float(numSamples))\n",
    "# plotter = Series(dist_pres)\n",
    "ax = plotter.plot.hist()  # s is an instance of Series\n",
    "fig = ax.get_figure()\n",
    "fig.savefig('figures/Abundance_combined.png')\n",
    "ax;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><a id=\"OXA\">Occupancy X Abundance</a></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "xs, ys =[], []\n",
    "for i in range(1,1000):\n",
    "    xs.append(i/1000.0)\n",
    "    ys.append(len(plotter[plotter > i/1000.0]))\n",
    "plt.plot(xs,ys)\n",
    "plt.xlabel('Percent of samples',fontsize=14)\n",
    "plt.ylabel('Rank Abundance',fontsize=14)\n",
    "plt.savefig(\"figures/OccupencyAbundance.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "xs, ys =[], []\n",
    "for contName in presAbs:\n",
    "    ys.append(presAbs[contName]/numSamples)\n",
    "    xs.append(abundance[contName])\n",
    "plt.plot(xs,ys,'ro')\n",
    "plt.xlabel('Abundance',fontsize=14)\n",
    "plt.ylabel('% Presence',fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id=\"pltao\">Filter the data by occupency and abundance</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numSamples = float(len(fileNames))\n",
    "# keeperContigs = set()\n",
    "# for contig, count in presAbs.items(): \n",
    "#     if count/float(numSamples) >= .25: keeperContigs.add(contig)\n",
    "print (\"Keeping %i contigs\" % (len(keeperContigs)))\n",
    "\n",
    "fileNames = glob(\"stats/combined/*.tsv\")\n",
    "presAbs,abundance = {},{}\n",
    "\n",
    "print(\"%i combined samples\"%(int(numSamples)))\n",
    "counter=0\n",
    "for fname in fileNames:\n",
    "    counter += 1\n",
    "    print(\"%i.\" % counter,fname)\n",
    "    ffh =  open(fname.replace(\"stats/combined/\",\"stats/combined/filtered/\"),\"w\")\n",
    "    for line in open(fname): \n",
    "        rec = line.strip().split()\n",
    "        if rec[0] in keeperContigs: \n",
    "            ffh.write(\"%s\\t%s\\n\" % (rec[0],rec[1]))\n",
    "            try:presAbs[rec[0]]     += int(int(rec[1]) > 0)\n",
    "            except:presAbs[rec[0]]   = int(int(rec[1]) > 0)\n",
    "            try:abundance[rec[0]]   += int(rec[1])\n",
    "            except:abundance[rec[0]] = int(rec[1])\n",
    "    ffh.close()\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "xs, ys =[], []\n",
    "for contName in presAbs:\n",
    "    xs.append(presAbs[contName]/numSamples)\n",
    "    ys.append(abundance[contName])\n",
    "plt.plot(xs,ys,'ro')\n",
    "plt.xlabel('Percent Abundance',fontsize=14)\n",
    "plt.ylabel('Abundance',fontsize=14)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileNames = glob(\"stats/combined/filtered/*.tsv\")\n",
    "allCounts = {}\n",
    "counter=0\n",
    "for fname in fileNames:\n",
    "    sampleName = fname.replace(\"stats/combined/filtered/\",\"\").replace(\".tsv\",\"\")\n",
    "    allCounts[sampleName]={}\n",
    "    counter+=1\n",
    "    print(\"%i. %s\"%(counter,sampleName))\n",
    "    for line in open(fname):\n",
    "        rec=line.strip().split()\n",
    "        allCounts[sampleName][rec[0]]=int(rec[1])\n",
    "dump(allCounts,open(\"pickles/sampleDict.p\",\"wb\"))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id=\"nmds\">NMDS</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleOrder = {}\n",
    "counter = 0\n",
    "dates=metadata[[\"sampling_date\",\"Date\"]]\n",
    "dates=dates.sort_values(by=\"Date\")\n",
    "dates=dates[\"sampling_date\"]\n",
    "    \n",
    "for date in dates.unique():\n",
    "    for crop in set(metadata.type):\n",
    "        for treatment in set(metadata.treatment):\n",
    "            sampleGroupMeta = metadata.loc[(metadata.sampling_date==date) & (metadata.treatment==treatment) & (metadata.type == crop)]\n",
    "            if len(sampleGroupMeta) == 0: continue\n",
    "            idName = \"%s_%s\" % (sampleGroupMeta.plot_name.unique()[0],date.replace(\"/\",\"_\"))\n",
    "            counter+=1\n",
    "            sampleOrder[idName] = counter\n",
    "\n",
    "print(\"Loading sample counts\")\n",
    "allCounts = load(open(\"pickles/sampleDict.p\",\"rb\"))\n",
    "allCounts = DataFrame(allCounts).transpose()\n",
    "allCounts['Rank'] = allCounts.index.to_series().map(sampleOrder)\n",
    "allCounts.sort_values('Rank',inplace = True)\n",
    "allCounts.drop('Rank', 1, inplace = True)\n",
    "allCounts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = np.random.RandomState(seed=3)\n",
    "allCounts_matrix = allCounts.as_matrix()\n",
    "similarities = euclidean_distances(allCounts_matrix)\n",
    "\n",
    "nsamples = len(allCounts)\n",
    "mds = manifold.MDS(n_components=2, max_iter=3000, eps=1e-9, random_state=seed, dissimilarity=\"precomputed\", n_jobs=1)\n",
    "pos = mds.fit(similarities).embedding_\n",
    "nmds = manifold.MDS(n_components=2, metric=False, max_iter=3000, eps=1e-12, dissimilarity=\"precomputed\", random_state=seed, n_jobs=1, n_init=1)\n",
    "npos = nmds.fit_transform(similarities, init=pos)\n",
    "\n",
    "fig = plt.figure(1)\n",
    "ax = plt.axes([0., 0., 1.5, 1.95])\n",
    "s = 100\n",
    "counter = 0\n",
    "group = 0\n",
    "totalGroups = nsamples/4\n",
    "l1s, l2s = [], []\n",
    "for date in dates.unique():\n",
    "    group+=1\n",
    "    l1s.append(\"SG-Fert \"+date)\n",
    "    plt.scatter(npos[counter:counter+1, 0], npos[counter:counter+1, 1], color=scolor(group,totalGroups,True), s=s, lw=0, label=\"SG-Fert \"+date,marker=\"^\")\n",
    "    counter+=1\n",
    "    l1s.append(\"SG-NF \"+date)\n",
    "    plt.scatter(npos[counter:counter+1, 0], npos[counter:counter+1, 1], color=scolor(group,totalGroups,True), s=s, lw=0, label=\"SG-NF \"+date,marker=\"v\")\n",
    "    counter+=1\n",
    "    l2s.append(\"MC-Fert \"+date)\n",
    "    plt.scatter(npos[counter:counter+1, 0], npos[counter:counter+1, 1], color=scolor(group,totalGroups,False), s=s, lw=0, label=\"MC-Fert \"+date,marker=\"p\")\n",
    "    counter+=1\n",
    "    l2s.append(\"MC-NF \"+date)\n",
    "    plt.scatter(npos[counter:counter+1, 0], npos[counter:counter+1, 1], color=scolor(group,totalGroups,False), s=s, lw=0, label=\"MC-NF \"+date,marker=\"H\")\n",
    "    counter+=1\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "# sort both labels and handles by labels\n",
    "# labels, handles = zip(*sorted(zip(labels, handles), key=lambda t: t[0]))\n",
    "# ax.legend(handles, labels)\n",
    "plt.legend(handles, labels,scatterpoints=1, loc='best', shadow=False)\n",
    "plt.title(\"Switchgrass(SG) and Miscanthus(MC) Fertilized(Fert) & Not Ferilized(NF) NMDS\")\n",
    "# plt.tight_layout()\n",
    "plt.savefig(\"figures/AllCombinedNMDS.png\",bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g6Data, g5Data = [],[]\n",
    "for key in allCounts.index:\n",
    "    if key[:2] == \"G5\": g5Data.append(key)\n",
    "    else: g6Data.append(key)\n",
    "g5Data = allCounts.drop(g5Data)\n",
    "g6Data = allCounts.drop(g6Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g5Data_matrix = g5Data.as_matrix()\n",
    "similarities = euclidean_distances(g5Data_matrix)\n",
    "nsamples = len(g5Data)\n",
    "mds = manifold.MDS(n_components=2, max_iter=3000, eps=1e-9, random_state=seed, dissimilarity=\"precomputed\", n_jobs=1)\n",
    "pos = mds.fit(similarities).embedding_\n",
    "nmds = manifold.MDS(n_components=2, metric=False, max_iter=3000, eps=1e-12, dissimilarity=\"precomputed\", random_state=seed, n_jobs=1, n_init=1)\n",
    "npos = nmds.fit_transform(similarities, init=pos)\n",
    "\n",
    "fig = plt.figure(1)\n",
    "ax = plt.axes([0., 0., 1.5, 1.95])\n",
    "s = 100\n",
    "\n",
    "for index, sample in enumerate(g5Data.index):\n",
    "    species = \"MC\"; \n",
    "    if sortedmeta[sortedmeta.nucleic_acid_name == sample].treatment[0] == \"nitrogen free\": \n",
    "        treatment = \"NF\"\n",
    "        marker = 'p'\n",
    "    else: \n",
    "        treatment = \"Fert\"\n",
    "        marker= \"s\"\n",
    "            \n",
    "    lbl = \"%s_%s\" % (species,treatment)\n",
    "    plt.scatter(npos[index:index+1, 0], npos[index:index+1, 1], color=scolor(index+71,72,species == \"SG\"), s=s, lw=0, label=lbl,marker=marker)\n",
    "\n",
    "#plt.legend(scatterpoints=1, loc='best', shadow=False)\n",
    "plt.title(\"Miscanthus (Fert) and Not Ferilized (NF)\")\n",
    "plt.savefig(\"figures/Miscanthus_NMDS_genes.png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g6Data_matrix = g6Data.as_matrix()\n",
    "similarities = euclidean_distances(g6Data_matrix)\n",
    "nsamples = len(g6Data)\n",
    "mds = manifold.MDS(n_components=2, max_iter=3000, eps=1e-9, random_state=seed, dissimilarity=\"precomputed\", n_jobs=1)\n",
    "pos = mds.fit(similarities).embedding_\n",
    "nmds = manifold.MDS(n_components=2, metric=False, max_iter=3000, eps=1e-12, dissimilarity=\"precomputed\", random_state=seed, n_jobs=1, n_init=1)\n",
    "npos = nmds.fit_transform(similarities, init=pos)\n",
    "\n",
    "fig = plt.figure(1)\n",
    "ax = plt.axes([0., 0., 1.5, 1.5])\n",
    "s = 100\n",
    "counter = 0\n",
    "group=0\n",
    "for index, sample in enumerate(g6Data.index):\n",
    "    species = \"SG\"; \n",
    "    if sortedmeta[sortedmeta.nucleic_acid_name == sample].treatment[0] == \"nitrogen free\": \n",
    "        treatment = \"NF\"\n",
    "        marker = '^'\n",
    "    else: \n",
    "        treatment = \"Fert\"\n",
    "        marker= \"v\"   \n",
    "    lbl = \"%s_%s\" % (species,treatment)\n",
    "    plt.scatter(npos[index:index+1, 0], npos[index:index+1, 1], color=scolor(index,72,species == \"SG\"), s=s, lw=0, label=lbl,marker=marker)\n",
    "\n",
    "#plt.legend(scatterpoints=1, loc='best', shadow=False)\n",
    "plt.title(\"Switchgrass Fertilized (Fert) and Not Ferilized (NF)\")\n",
    "plt.savefig(\"figures/Switchgrass_NMDS_genes.png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><a id=\"metaT\">Function Analysis</a></h1>\n",
    "\n",
    "[Home](#meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KO_Levels = DataFrame.from_csv(\"annotations/KO_Levels.tsv\",sep='\\t')\n",
    "KO_Levels['Level1'] = KO_Levels['Level1'].apply(lambda x: str(x).zfill(5))\n",
    "KO_Levels['Level2'] = KO_Levels['Level2'].apply(lambda x: str(x).zfill(5))\n",
    "KO_Levels['Level3'] = KO_Levels['Level3'].apply(lambda x: str(x).zfill(5))\n",
    "KO_Levels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contigKOs = {}\n",
    "koContigs = {}\n",
    "for line in open(\"annotations/KEGG_tools_out/diamondAnnotations_0_KOtable.txt\"):\n",
    "    rec = line.split('\\t')\n",
    "    try: contigKOs[rec[0]].add(rec[2])\n",
    "    except: contigKOs[rec[0]] = set([rec[2]])\n",
    "    try: koContigs[rec[2]].add(rec[0])\n",
    "    except: koContigs[rec[2]] = set([rec[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allCounts = load(open(\"pickles/allCounts_genes.p\",\"rb\")) \n",
    "ko_mapper = load(open(\"pickles/koMap.p\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import log2\n",
    "levels = KO_Levels.Level1.unique()\n",
    "Level3DF = DataFrame(index=levels, columns=allCounts.columns)\n",
    "Level3DF = Level3DF.fillna(0)\n",
    "for level in levels:\n",
    "    selectedKOs = KO_Levels[KO_Levels.Level1 == level]\n",
    "    selectedContigs = set()\n",
    "    for ko in selectedKOs.index: selectedContigs = selectedContigs.union(koContigs[ko])\n",
    "    selectedCounts = allCounts[allCounts.index.isin(selectedContigs)]\n",
    "    countSums = selectedCounts.sum(axis=0)\n",
    "    countSums = readsForAllContigs\n",
    "    countSums = log2(countSums/readCounts[\"TotalSampleReads\"])\n",
    "    Level3DF.loc[level] = countSums\n",
    "Level3DF[\"Description\"] = Level3DF.index.to_series().map(ko_mapper.descripts)\n",
    "cols = Level3DF.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "Level3DF = Level3DF[cols]\n",
    "Level3DF=Level3DF.set_index('Description')\n",
    "Level3DF.to_csv(\"annotations/Level1CountTable.tsv\",sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readCounts = read_csv(\"mapping/metaG/flagstats/multiqc_data/mqc_bowtie2_pe_plot_1.txt\",sep=\"\\t\")\n",
    "readCounts[\"TotalSampleReads\"] = data.sum(axis=1)\n",
    "readCounts.set_index(\"Sample\",inplace=True)\n",
    "readCounts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KO_Mapper:\n",
    "    def __init__(self):\n",
    "        self.koToMap = {}\n",
    "        self.descripts = {}\n",
    "        self.mapToKO = {}\n",
    "        self.levelToMap = {}\n",
    "        self.ko = \"\"\n",
    "        self.KEGG_URL = \"https://www.kegg.jp/dbget-bin/www_bget?%s\"\n",
    "\n",
    "    def setItem(self, level, mapNum, descrip):\n",
    "        # print(self.ko, level, mapNum, descrip)\n",
    "        # Map descriptions\n",
    "        self.descripts[mapNum] = descrip\n",
    "        \n",
    "        # Map to KO\n",
    "        try: self.mapToKO[mapNum].add(self.ko)\n",
    "        except: self.mapToKO[mapNum] = set([self.ko])\n",
    "        \n",
    "        # KO to level to mapNum\n",
    "        try: self.koToMap[self.ko][level].add(mapNum)\n",
    "        except: \n",
    "            try: self.koToMap[self.ko][level] = set([mapNum])\n",
    "            except: self.koToMap[self.ko] = { level:set([mapNum]) }\n",
    "        \n",
    "        # Level to map\n",
    "        try: self.levelToMap[level].add(mapNum)\n",
    "        except: self.levelToMap[level] = set([mapNum])\n",
    "                \n",
    "    def _processKOInfo(self, koText):\n",
    "        rec = koText.strip().split('\\n')\n",
    "        while 'KEGG Orthology' not in rec[0] and len(rec)>0: rec = rec[1:]\n",
    "        if len(rec)==0:return\n",
    "        for line in rec[1:]:\n",
    "            level = line.count('\\xa0')\n",
    "            if (level == 0) or self.ko in str(line): break #Don't record any ribosome info\n",
    "            info = line.strip('\\xa0')\n",
    "            bIndex = info.find(\" \")\n",
    "            self.setItem(level,info[:bIndex],info[bIndex+1:])\n",
    "    \n",
    "    def mapKO(self,ko):\n",
    "        siteContent = BeautifulSoup(urlopen(self.KEGG_URL%(ko)).read(),features=\"lxml\")\n",
    "        self.ko = ko\n",
    "        found = False\n",
    "        for i, elm in enumerate(siteContent.find_all(\"td\", {\"class\": \"td41\"})):\n",
    "            if \"KEGG Orthology\" in str(elm.contents[0]):\n",
    "                pathway = elm.find(\"nobr\")\n",
    "                self._processKOInfo(pathway.text)\n",
    "                found = True\n",
    "                break\n",
    "        if not found: \n",
    "            for i, elm in enumerate(siteContent.find_all(\"td\", {\"class\": \"td40\"})):\n",
    "                if \"KEGG Orthology\" in str(elm.contents[0]):\n",
    "                    pathway = elm.find(\"nobr\")\n",
    "                    self._processKOInfo(pathway.text)\n",
    "                    found = True\n",
    "                    break\n",
    "        if not found: raise Exception(\"Unable to find \" + self.ko)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame.read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A custom function to help us find the raw fastq files\n",
    "from glob import glob\n",
    "rawFastqFiles = glob('jgi_transfer/metaT_raw/*/Raw_Data/*')\n",
    "\n",
    "def lookupFSTQ(name,rawFastqFiles):\n",
    "    fastqName = ''\n",
    "    found = False\n",
    "    for fastqName in rawFastqFiles:\n",
    "        if name in fastqName: \n",
    "            found = True\n",
    "            break\n",
    "    if found:\n",
    "        rawFastqFiles.remove(fastqName)\n",
    "        return fastqName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "ls metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame, to_datetime\n",
    "#Collect Metadata\n",
    "metadata = DataFrame.from_csv(\"metadata/GLBRC_MetaT_Metadata.tsv\",sep='\\t')\n",
    "\n",
    "#Change the data to only include things we are interested in and format a few columns\n",
    "metadata['sampling_date'] = to_datetime(metadata.date) #Make date a format python can sort\n",
    "metadata.drop(['time','air_temp_c', 'day', 'month', 'year', 'weather', 'notes', 'rep', 'date_of_extraction', 'nucleic_acid_type', \n",
    "   'replicate_extraction', 'source', 'source_mass', 'extraction_method', 'elution_vol_ul', 'concentration_ng_per_ul', \n",
    "   'ratio_260_280', 'conc_ng_per_g_source', 'extracted_by', 'sequencing_date', 'conc_sent_ng_per_ul', 'sequencing_type', \n",
    "   'sequencing_facility', 'primers', 'submitted_for_sequencing', 'sequencing_successful', 'duplicate_submitted', 'dup_sequencing_name', \n",
    "   'exclude_from_analysis', 'itemID_JGI', 'sampleID_JGI', 'JGI_rawdataname', 'Air_Pressure', 'RH', 'AH', 'Wind_Speed_Mean', 'PAR', \n",
    "   'soil_temp_5_cm_bare_avg', 'soil_temp_5_cm_sod_avg', 'Year', 'date', 'pseudorep','MMPRNT_ID','time_zone','longitude', 'country',\n",
    "   'location','air_temp_max','Air_Temp_Min','latitude','altitude','plot_name', 'soil_name', 'number_cores', 'Air_temp_mean' ,\n",
    "   'Wind_Direction_Mean','time_numeric','precipitation', 'Solar_Radiation','pH','JGI_taxonOID','JGI_library','SPNL_date','lime_index',\n",
    "   'P_ppm','barcode','K_ppm', 'Ca_ppm', 'Mg_ppm', 'organic_matter', 'NO3N_ppm', 'NH4_ppm', 'soil_moisture_percent', 'soil_temp_10cm', \n",
    "   'plant_name', 'LDMC_mg_per_g', 'nitrogen_percent', 'carbon_percent', 'carbon_per_nitrogen', 'height_mean_cm', 'mass_per_leaf_g',\n",
    "   'name','plotID','sequence_name'],axis=1,inplace=True)\n",
    "metadata = metadata.rename(index=str, columns={'nucleic_acid_name':'name'})\n",
    "\n",
    "#Map Metadata to fastq files\n",
    "metadata['HPCC_path'] = metadata.apply(lambda row: lookupFSTQ(row['name'],rawFastqFiles), axis=1)\n",
    "\n",
    "#Sort the metadata for ordering purposes\n",
    "metadata.sort_values(by=['plant','sampling_date','treatment','name'],inplace=True) #,\"Date\",\"treatment\",\"plot_name\"])\n",
    "\n",
    "#Change the Identifier\n",
    "metadata.set_index('name',inplace=True)\n",
    "\n",
    "#Show me the top 10\n",
    "print(metadata.shape)\n",
    "metadata.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "rawDirs = listdir(\"jgi_transfer/metaT_raw/\") #*/Raw_Data/*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import system\n",
    "# links = glob(\"mapping/metaT/unpaired/*.fastq.gz\")\n",
    "# for lnk in links: system(\"unlink \"+lnk)\n",
    "from os import listdir\n",
    "rawDirs = listdir(\"jgi_transfer/metaT_raw/\") #*/Raw_Data/*\n",
    "#Make Sym links to put fastqs in same dir\n",
    "from os import system\n",
    "for sample_name in metadata.index:\n",
    "    if metadata.loc[sample_name,'HPCC_path']:\n",
    "        pass\n",
    "#         system(\"ln -s /mnt/research/ShadeLab/GLBRC/%s mapping/metaT/unpaired/%s.fastq.gz\" % (metadata.loc[sample_name,'HPCC_path'],sample_name))\n",
    "    else: \n",
    "        sample_name = sample_name[:sample_name.rfind(\"_\")]\n",
    "        \n",
    "#         for fname in rawDirs:\n",
    "        print(\"Missing metadata for\",sample_name)\n",
    "# for fname in rawFastqFiles: print(\"Missing Metadata:\",fname[fname.find(\"function__\")+10:fname.find(\"_MT_\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "ls jgi_transfer/metaT_raw/ |wc -l\n",
    "cd jgi_transfer/metaT_raw/*G5R4_NF_12JUL2016*\n",
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "ls mapping/metaT/unpaired/ |wc -l\n",
    "ls mapping/metaT/unpaired/*12JUL2016*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N-Dimensional Scaling\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.collections import LineCollection\n",
    "from sklearn import manifold\n",
    "from sklearn.metrics import euclidean_distances\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.spatial import distance\n",
    "\n",
    "n_samples = 20\n",
    "seed = np.random.RandomState(seed=3)\n",
    "X_true = seed.randint(0, 20, 2 * n_samples).astype(np.float)\n",
    "print(X_true)\n",
    "X_true = X_true.reshape((n_samples, 2))\n",
    "\n",
    "# Center the data\n",
    "# X_true -= X_true.mean()\n",
    "\n",
    "similarities = euclidean_distances(X_true)\n",
    "#print(similarities)\n",
    "\n",
    "# Add noise to the similarities\n",
    "noise = np.random.rand(n_samples, n_samples)\n",
    "noise = noise + noise.T\n",
    "noise[np.arange(noise.shape[0]), np.arange(noise.shape[0])] = 0\n",
    "# similarities += noise\n",
    "\n",
    "mds = manifold.MDS(n_components=2, max_iter=3000, eps=1e-9, random_state=seed, dissimilarity=\"precomputed\", n_jobs=1)\n",
    "pos = mds.fit(similarities).embedding_\n",
    "\n",
    "nmds = manifold.MDS(n_components=2, metric=False, max_iter=3000, eps=1e-12, dissimilarity=\"precomputed\", random_state=seed, n_jobs=1, n_init=1)\n",
    "npos = nmds.fit_transform(similarities, init=pos)\n",
    "\n",
    "# Rescale the data\n",
    "# pos *= np.sqrt((X_true ** 2).sum()) / np.sqrt((pos ** 2).sum())\n",
    "# npos *= np.sqrt((X_true ** 2).sum()) / np.sqrt((npos ** 2).sum())\n",
    "\n",
    "# Rotate the data\n",
    "clf = PCA(n_components=2)\n",
    "X_true = clf.fit_transform(X_true)\n",
    "\n",
    "pos = clf.fit_transform(pos)\n",
    "npos = clf.fit_transform(npos)\n",
    "\n",
    "fig = plt.figure(1)\n",
    "ax = plt.axes([0., 0., 1., 1.])\n",
    "\n",
    "s = 100\n",
    "plt.scatter(X_true[:, 0], X_true[:, 1], color='navy', s=s, lw=0, label='True Position')\n",
    "plt.scatter(pos[:, 0], pos[:, 1], color='turquoise', s=s, lw=0, label='MDS')\n",
    "plt.scatter(npos[:, 0], npos[:, 1], color='darkorange', s=s, lw=0, label='NMDS')\n",
    "plt.legend(scatterpoints=1, loc='best', shadow=False)\n",
    "similarities = similarities.max() / similarities * 100\n",
    "similarities[np.isinf(similarities)] = 0\n",
    "\n",
    "# Plot the edges\n",
    "start_idx, end_idx = np.where(pos)\n",
    "# a sequence of (*line0*, *line1*, *line2*), where::\n",
    "#            linen = (x0, y0), (x1, y1), ... (xm, ym)\n",
    "segments = [[X_true[i, :], X_true[j, :]]\n",
    "            for i in range(len(pos)) for j in range(len(pos))]\n",
    "values = np.abs(similarities)\n",
    "lc = LineCollection(segments, zorder=0, cmap=plt.cm.Blues, norm=plt.Normalize(0, values.max()))\n",
    "lc.set_array(similarities.flatten())\n",
    "lc.set_linewidths(np.full(len(segments), 0.5))\n",
    "ax.add_collection(lc)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.SeqIO import parse\n",
    "dist = []\n",
    "for rec in parse(\"assemblies/final.contigs.fa\",\"fasta\"): dist.append(len(rec.seq))\n",
    "dist = Series(dist)\n",
    "dist.plot.hist();\n",
    "print(dist.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist.plot.bar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GetOrfs import getOrfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "nfiles = 1\n",
    "fname = \"contigs2/%i.fasta\" % (counter)\n",
    "fh = open(\"contigs2/%i.fasta\" % (counter),\"w\")\n",
    "for rec in parse(\"/mnt/scratch/howead/glbrc/assembly/final.contigs.fa\",\"fasta\"): \n",
    "    write(rec,fh,\"fasta\")\n",
    "    counter+=1\n",
    "    if (counter % 5000 == 0):\n",
    "        fh.close()\n",
    "        getOrfs(fname)\n",
    "        nfiles+=1\n",
    "        fname = \"contigs2/%i.fasta\" % (counter)\n",
    "        fh = open(\"contigs2/%i.fasta\" % (counter),\"w\")\n",
    "fh.close()\n",
    "#pickle.dump(contigNames,open(\"SeqIDs.p\", \"wb\"))\n",
    "#contigNames = pickle.load(open(\"SeqIDs.p\", \"rb\"))\n",
    "#files = glob(\"bams/*.bam\")\n",
    "print(nfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "ls -alh pickles/G5R3_NF_31MAY2016_LD1_counts.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "files = glob(\"stats/*.tsv\")\n",
    "print (\"Number of files:\",len(files))\n",
    "smallFile = open(\"testFile.txt\",\"w\")\n",
    "\n",
    "for statFile in files:\n",
    "    counter = 0\n",
    "    readsFileName = statFile.replace(\"stats/\",\"\").replace(\".tsv\",\"\")\n",
    "    sampleMeta = metadata[metadata.index == readsFileName]\n",
    "    curSampleID = sampleMeta.nucleic_acid_name.values[0]\n",
    "\n",
    "    fname = \"pickles/%s_counts.p\" % (curSampleID)\n",
    "    fh = open(fname,\"rb\")\n",
    "    data = pickle.load(fh)\n",
    "    print(data)\n",
    "    break\n",
    "\n",
    "smallFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from os import path\n",
    "sample_data = {}\n",
    "files = glob(\"stats/*.tsv\")\n",
    "print (\"Number of files:\",len(files))\n",
    "counter = 0\n",
    "for statFile in files:\n",
    "    readsFileName = statFile.replace(\"stats/\",\"\").replace(\".tsv\",\"\")\n",
    "    sampleMeta = metadata[metadata.index == readsFileName]\n",
    "    curSampleID = sampleMeta.nucleic_acid_name.values[0]\n",
    "    sample_data={}\n",
    "    counter+=1\n",
    "    print (\"%i. %s\" % (counter, curSampleID))\n",
    "#     if path.exists(\"pickles/%s_counts.p\" % (curSampleID)):continue#\n",
    "#     for line in open(statFile):\n",
    "#         rec = line.strip().split()\n",
    "#         sample_data[rec[0]] = int(rec[2]) #How can an unmapped read be connected to a contig?\n",
    "#     pickle.dump(sample_data,open(\"pickles/%s_counts.p\" % (curSampleID),\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dimensional Reduction\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.collections import LineCollection\n",
    "from sklearn import manifold\n",
    "from sklearn.metrics import euclidean_distances\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkSkipRead(read,reads):\n",
    "    # 1. Read is unmapped\n",
    "    # 2. Read pair has already been seen \n",
    "    # 3. Read doesn't map well\n",
    "    return read.is_unmapped or read.qname in reads or read.mapping_quality <= 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "for bamFileName in files:\n",
    "    contigCounter = contigNames.copy()\n",
    "    samfile = pysam.AlignmentFile(bamFileName, \"rb\")\n",
    "    readsFileName = bamFileName.replace(\"bams/\",\"\").replace(\".sorted.bam\",\"\")\n",
    "    print readsFileName\n",
    "    sampleMeta = metadata[metadata.index == readsFileName]\n",
    "    nuceID = sampleMeta.nucleic_acid_name.get_values()[0]\n",
    "    countsFile = open(\"counts/%s.txt\" % (nuceID),\"w\")\n",
    "    reads=set()\n",
    "    for read in samfile:\n",
    "        if checkSkipRead(read,reads):continue \n",
    "        reads.add(read.qname)\n",
    "    countsFile.close()\n",
    "    break\n",
    "print coninues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print samFileName\n",
    "counter = 0\n",
    "for name in contigCounter:\n",
    "    print name, samfile.count(name)\n",
    "    counter +=1\n",
    "    if counter == 10: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Number of unmapped\",unmapped\n",
    "print coninues-unmapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print read.reference_name\n",
    "print samFileName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contname = contigNames.keys()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob(\"stats/*.tsv\")\n",
    "sampleStats = {}\n",
    "for statFile in files:\n",
    "    sampleFileName = statFile.replace(\"stats/\",\"\").replace(\".tsv\",\"\")\n",
    "    sampleMeta = metadata[metadata.index == sampleFileName]\n",
    "    nuceID = sampleMeta.nucleic_acid_name.get_values()[0]\n",
    "    for line in open(statFile):\n",
    "        rec = line.strip().split()\n",
    "        contigNames[rec[0]] = int(rec[2])\n",
    "    sampleStats[nuceID] = contigNames\n",
    "import pickle\n",
    "pickle.dump(sampleStats,open(\"sampleCounts.p\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(samfile.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for id in metadata.index:\n",
    "    if '11505.2.209522.CACCTTA-GTAAGGT.fastq.gz' in id: \n",
    "        counter += 1\n",
    "        print id,\n",
    "        if counter % 2 == 0:print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleMeta = metadata[metadata.index == readsFileName]\n",
    "sampleMeta.nucleic_acid_name.get_values()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samFileName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec.is_qcfail\n",
    "rec.is_read1\n",
    "dir(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 10**(-(ord('3')-33)/10.0)\n",
    "print 10.0**(-(ord('3')-33.0)/10.0)\n",
    "print 10**(-(ord('3')-33)/10)\n",
    "print 10**(-(ord('3')-33.0)/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "fh=open(\"CombinedStats.tsv\",\"w\")\n",
    "fh.write(\"Contig\")\n",
    "\n",
    "for fname in glob(\"stats/*.tsv\"):\n",
    "    print(fname)\n",
    "    readsFileName = fname.replace(\"stats/\",\"\").replace(\".tsv\",\"\")\n",
    "    sampleMeta = metadata[metadata.index == readsFileName]\n",
    "    curSampleID = sampleMeta.nucleic_acid_name.values[0]\n",
    "    fh.write(\"\\t\"+curSampleID)\n",
    "\n",
    "\n",
    "#Get the column identifier\n",
    "init_fname = \"stats/11425.3.206650.ACGGTCT-AAGACCG.fastq.gz.tsv\"\n",
    "for line in open(init_fname):\n",
    "    rec = line.strip().split()\n",
    "    fh.write(\"\\t\"+rec[0])\n",
    "fh.write(\"\\n\")\n",
    "\n",
    "#Read all the files\n",
    "for fname in glob(\"stats/*.tsv\"):\n",
    "    print(fname)\n",
    "    readsFileName = fname.replace(\"stats/\",\"\").replace(\".tsv\",\"\")\n",
    "    sampleMeta = metadata[metadata.index == readsFileName]\n",
    "    curSampleID = sampleMeta.nucleic_acid_name.values[0]\n",
    "    fh.write(curSampleID)\n",
    "    for line in open(fname):\n",
    "        rec = line.strip().split()\n",
    "        fh.write(\"\\t\"+rec[2])\n",
    "    fh.write(\"\\n\")\n",
    "fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import linecache\n",
    "from glob import glob\n",
    "# fh = open(\"CombinedStats_T.tsv\",\"w\")\n",
    "# fh.write(\"\\t\")\n",
    "fileNames = glob(\"stats/*.tsv\")\n",
    "\n",
    "# #Write the header line\n",
    "# for fname in fileNames:\n",
    "#     readsFileName = fname.replace(\"stats/\",\"\").replace(\".tsv\",\"\")\n",
    "#     sampleMeta = metadata[metadata.index == readsFileName]\n",
    "#     curSampleID = sampleMeta.nucleic_acid_name.values[0]\n",
    "#     fh.write(\"\\t\"+curSampleID)\n",
    "# fh.write(\"\\n\")\n",
    "\n",
    "#get the row starters\n",
    "pres_abs = {}\n",
    "total_count =\n",
    "init_fname = \"stats/11425.3.206650.ACGGTCT-AAGACCG.fastq.gz.tsv\"\n",
    "for line in open(init_fname): rows.append(line.strip().split()[0])\n",
    "print(\"Done getting contig names\")\n",
    "fh = open(\"combined/CombinedStats_T%i.tsv\" % 0 ,\"w\")\n",
    "val={0:\"\"}\n",
    "for i in range(1,12301484):\n",
    "    print(i,end=\" \")\n",
    "    fh.write(rows[i-1])\n",
    "    for fname in fileNames: fh.write(\"\\t\"+linecache.getline(fname, i))\n",
    "    fh.write(\"\\n\")\n",
    "    try:\n",
    "        val[i %  5000] = 1\n",
    "        print(i,end=\" \")\n",
    "        fh.close()\n",
    "        fh = open(\"combined/CombinedStats_T%i.tsv\" % i ,\"w\")\n",
    "    except:pass\n",
    "        \n",
    "print(\"Done\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Presence absence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pickle\n",
    "fileNames = glob(\"stats/*.tsv\")\n",
    "presAbs,abundance = {},{}\n",
    "\n",
    "for fname in fileNames:\n",
    "    print(fname)\n",
    "    for line in open(fname): \n",
    "        rec = line.strip().split()\n",
    "        try:presAbs[rec[0]] += int(int(rec[2]) > 0)\n",
    "        except:presAbs[rec[0]] = int(int(rec[2]) > 0)\n",
    "        try:abundance[rec[0]] += int(rec[2])\n",
    "        except:abundance[rec[0]] = int(rec[2])\n",
    "\n",
    "pickle.dump(presAbs,open(\"presence_Absence.p\",\"wb\"))    \n",
    "pickle.dump(abundance,open(\"abundance.p\",\"wb\"))   \n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_abu = []\n",
    "print(int(len(fileNames)*.7),len(fileNames))\n",
    "numSamples = float(len(fileNames))\n",
    "for contig, count in abundance.items(): dist_abu.append(count/numSamples)\n",
    "    \n",
    "from pandas import Series\n",
    "dist = Series(dist_abu)\n",
    "dist.plot.hist();\n",
    "dist.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining Sample Counts\n",
    "\n",
    "allCounts = load(open(\"pickles/allCounts_genes.p\",\"rb\")) \n",
    "\n",
    "combined_abundance = {}\n",
    "for crop in set(metadata.type):\n",
    "    for date in set(metadata.sampling_date):\n",
    "        for treatment in set(metadata.treatment):\n",
    "            sampleGroupMeta = metadata.loc[(metadata.sampling_date==date) & (metadata.treatment==treatment) & (metadata.type == crop)]\n",
    "            groupName = \"%s_%s_%s\" % (crop,treatment.replace(\" \",\"\").replace(\"f\",\"F\"),date)\n",
    "            if len(sampleGroupMeta) == 0: continue\n",
    "            print(groupName)\n",
    "            combined_abundance[groupName]= {}\n",
    "            for sampleName in sampleGroupMeta.nucleic_acid_name:\n",
    "                #print(sampleName,len(allCounts[sampleName]))\n",
    "                for rec,count in allCounts[sampleName].items():\n",
    "                    try:combined_abundance[groupName][rec] += count\n",
    "                    except:combined_abundance[groupName][rec] = count\n",
    "allCounts = DataFrame(combined_abundance)\n",
    "allCounts[\"Average\"] = allCounts.sum(axis=1)/float(len(metadata.index))\n",
    "allCounts[\"Average\"].head()\n",
    "#allCounts.drop(\"Average\",axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in metadata.index:\n",
    "    sampMet = metadata[metadata.index == fname]\n",
    "    sampleID = sampMet.nucleic_acid_name.unique()[0]\n",
    "    #print(\"mv mapping/flagstats/%s.stat mapping/flagstats/%s.stat\" % (fname,sampleID))\n",
    "    \n",
    "    res = os.system(\"mv mapping/flagstats/%s.stat mapping/flagstats/%s.txt\" % (sampleID,sampleID))\n",
    "    print(fname,res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v= MultiqcModule()\n",
    "v = FlagstatReportMixin()\n",
    "v.parse_samtools_flagstats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from collections import OrderedDict\n",
    "import logging\n",
    "import re\n",
    "\n",
    "from multiqc import config\n",
    "from multiqc.plots import bargraph\n",
    "from multiqc.modules.base_module import BaseMultiqcModule\n",
    "# from multiqc.utils import config as mqcConfig\n",
    "# def load_config():\n",
    "#     my_search_patterns = {\n",
    "#         'my_plugin/my_mod': {'fn': '*_somefile.txt'},\n",
    "#         'my_plugin/my_other_mod': {'fn': '*other_file.txt'},\n",
    "#     }\n",
    "#     mqcConfig.update_dict(config.sp, my_search_patterns)\n",
    "\n",
    "\n",
    "# Initialise the logger\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "class MultiqcModule(BaseMultiqcModule):\n",
    "    \"\"\" Bowtie 2 module, parses stderr logs. \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        # Initialise the parent object\n",
    "        super(MultiqcModule, self).__init__(name=\"Bowtie 2\", anchor=\"stat\",\n",
    "        href='http://bowtie-bio.sourceforge.net/bowtie2/',\n",
    "        info=\"is an ultrafast and memory-efficient tool for aligning sequencing\"\\\n",
    "                \" reads to long reference sequences.\")\n",
    "\n",
    "        # Find and load any Bowtie 2 reports\n",
    "        self.bowtie2_data = dict()\n",
    "        self.num_se = 0\n",
    "        self.num_pe = 0\n",
    "        print(dir(self.find_log_files))\n",
    "        print(\"\")\n",
    "        print(help(self.find_log_files))\n",
    "        for f in self.find_log_files('mapping/flagstats', filehandles=True):\n",
    "            self.parse_bowtie2_logs(f)\n",
    "\n",
    "        # Filter to strip out ignored sample names\n",
    "        self.bowtie2_data = self.ignore_samples(self.bowtie2_data)\n",
    "\n",
    "        if len(self.bowtie2_data) == 0:\n",
    "            raise UserWarning\n",
    "\n",
    "        log.info(\"Found {} reports\".format(len(self.bowtie2_data)))\n",
    "\n",
    "        # Write parsed report data to a file\n",
    "        self.write_data_file(self.bowtie2_data, 'multiqc_bowtie2')\n",
    "\n",
    "        # Basic Stats Table\n",
    "        # Report table is immutable, so just updating it works\n",
    "        self.bowtie2_general_stats_table()\n",
    "\n",
    "        # Alignment Rate Plot\n",
    "        self.bowtie2_alignment_plot()\n",
    "\n",
    "\n",
    "    def parse_bowtie2_logs(self, f):\n",
    "        \"\"\"\n",
    "        Warning: This function may make you want to stab yourself.\n",
    "        Parse logs from bowtie2. These miss several key bits of information\n",
    "        such as input files, so we try to look for logs from other wrapper tools\n",
    "        that may have logged this info. If not found, we default to using the filename.\n",
    "        Note that concatenated logs only parse if we have the command printed in there.\n",
    "        The bowtie log uses the same strings mulitple times in different contexts to mean\n",
    "        different things, making parsing very messy. Handle with care.\n",
    "        Example single-end output from bowtie2:\n",
    "            Time loading reference: 00:00:08\n",
    "            Time loading forward index: 00:00:16\n",
    "            Time loading mirror index: 00:00:09\n",
    "            [samopen] SAM header is present: 25 sequences.\n",
    "            Multiseed full-index search: 00:58:04\n",
    "            38377305 reads; of these:\n",
    "              38377305 (100.00%) were unpaired; of these:\n",
    "                2525577 (6.58%) aligned 0 times\n",
    "                27593593 (71.90%) aligned exactly 1 time\n",
    "                8258135 (21.52%) aligned >1 times\n",
    "            93.42% overall alignment rate\n",
    "            Time searching: 00:58:37\n",
    "            Overall time: 00:58:37\n",
    "        Example paired-end output from bowtie2:\n",
    "            Time loading reference: 00:01:07\n",
    "            Time loading forward index: 00:00:26\n",
    "            Time loading mirror index: 00:00:09\n",
    "            Multiseed full-index search: 01:32:55\n",
    "            15066949 reads; of these:\n",
    "              15066949 (100.00%) were paired; of these:\n",
    "                516325 (3.43%) aligned concordantly 0 times\n",
    "                11294617 (74.96%) aligned concordantly exactly 1 time\n",
    "                3256007 (21.61%) aligned concordantly >1 times\n",
    "                ----\n",
    "                516325 pairs aligned concordantly 0 times; of these:\n",
    "                  26692 (5.17%) aligned discordantly 1 time\n",
    "                ----\n",
    "                489633 pairs aligned 0 times concordantly or discordantly; of these:\n",
    "                  979266 mates make up the pairs; of these:\n",
    "                    592900 (60.55%) aligned 0 times\n",
    "                    209206 (21.36%) aligned exactly 1 time\n",
    "                    177160 (18.09%) aligned >1 times\n",
    "            98.03% overall alignment rate\n",
    "            Time searching: 01:34:37\n",
    "            Overall time: 01:34:37\n",
    "        \"\"\"\n",
    "\n",
    "        # Regexes\n",
    "        regexes = {\n",
    "            'unpaired': {\n",
    "                'unpaired_aligned_none': r\"(\\d+) \\([\\d\\.]+%\\) aligned 0 times\",\n",
    "                'unpaired_aligned_one': r\"(\\d+) \\([\\d\\.]+%\\) aligned exactly 1 time\",\n",
    "                'unpaired_aligned_multi': r\"(\\d+) \\([\\d\\.]+%\\) aligned >1 times\"\n",
    "            },\n",
    "            'paired': {\n",
    "                'paired_aligned_none': r\"(\\d+) \\([\\d\\.]+%\\) aligned concordantly 0 times\",\n",
    "                'paired_aligned_one': r\"(\\d+) \\([\\d\\.]+%\\) aligned concordantly exactly 1 time\",\n",
    "                'paired_aligned_multi': r\"(\\d+) \\([\\d\\.]+%\\) aligned concordantly >1 times\",\n",
    "                'paired_aligned_discord_one': r\"(\\d+) \\([\\d\\.]+%\\) aligned discordantly 1 time\",\n",
    "                'paired_aligned_discord_multi': r\"(\\d+) \\([\\d\\.]+%\\) aligned discordantly >1 times\",\n",
    "                'paired_aligned_mate_one': r\"(\\d+) \\([\\d\\.]+%\\) aligned exactly 1 time\",\n",
    "                'paired_aligned_mate_multi': r\"(\\d+) \\([\\d\\.]+%\\) aligned >1 times\",\n",
    "                'paired_aligned_mate_none': r\"(\\d+) \\([\\d\\.]+%\\) aligned 0 times\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # Go through log file line by line\n",
    "        s_name = f['s_name']\n",
    "        parsed_data = {}\n",
    "\n",
    "        for l in f['f']:\n",
    "            # Attempt in vain to find original bowtie2 command, logged by another program\n",
    "            btcmd = re.search(r\"bowtie2 .+ -[1U] ([^\\s,]+)\", l)\n",
    "            if btcmd:\n",
    "                s_name = self.clean_s_name(btcmd.group(1), f['root'])\n",
    "                log.debug(\"Found a bowtie2 command, updating sample name to '{}'\".format(s_name))\n",
    "\n",
    "            # Total reads\n",
    "            total = re.search(r\"(\\d+) reads; of these:\", l)\n",
    "            if total:\n",
    "                parsed_data['total_reads'] = int(total.group(1))\n",
    "\n",
    "            # Single end reads\n",
    "            unpaired = re.search(r\"(\\d+) \\([\\d\\.]+%\\) were unpaired; of these:\", l)\n",
    "            if unpaired:\n",
    "                parsed_data['unpaired_total'] = int(unpaired.group(1))\n",
    "                self.num_se += 1\n",
    "\n",
    "                # Do nested loop whilst we have this level of indentation\n",
    "                l = f['f'].readline()\n",
    "                while l.startswith('    '):\n",
    "                    for k, r in regexes['unpaired'].items():\n",
    "                        match = re.search(r, l)\n",
    "                        if match:\n",
    "                            parsed_data[k] = int(match.group(1))\n",
    "                    l = f['f'].readline()\n",
    "\n",
    "            # Paired end reads\n",
    "            paired = re.search(r\"(\\d+) \\([\\d\\.]+%\\) were paired; of these:\", l)\n",
    "            if paired:\n",
    "                parsed_data['paired_total'] = int(paired.group(1))\n",
    "                self.num_pe += 1\n",
    "\n",
    "                # Do nested loop whilst we have this level of indentation\n",
    "                l = f['f'].readline()\n",
    "                while l.startswith('    '):\n",
    "                    for k, r in regexes['paired'].items():\n",
    "                        match = re.search(r, l)\n",
    "                        if match:\n",
    "                            parsed_data[k] = int(match.group(1))\n",
    "                    l = f['f'].readline()\n",
    "\n",
    "            # Overall alignment rate\n",
    "            overall = re.search(r\"([\\d\\.]+)% overall alignment rate\", l)\n",
    "            if overall:\n",
    "                parsed_data['overall_alignment_rate'] = float(overall.group(1))\n",
    "\n",
    "                # End of log section\n",
    "                # Save half 'pairs' of mate counts\n",
    "                m_keys = ['paired_aligned_mate_multi', 'paired_aligned_mate_none', 'paired_aligned_mate_one']\n",
    "                for k in m_keys:\n",
    "                    if k in parsed_data:\n",
    "                        parsed_data['{}_halved'.format(k)] = float(parsed_data[k]) / 2.0\n",
    "                # Save parsed data\n",
    "                if s_name in self.bowtie2_data:\n",
    "                    log.debug(\"Duplicate sample name found! Overwriting: {}\".format(s_name))\n",
    "                self.add_data_source(f, s_name)\n",
    "                self.bowtie2_data[s_name] = parsed_data\n",
    "                # Reset in case we find more in this log file\n",
    "                s_name = f['s_name']\n",
    "                parsed_data = {}\n",
    "\n",
    "\n",
    "    def bowtie2_general_stats_table(self):\n",
    "        \"\"\" Take the parsed stats from the Bowtie 2 report and add it to the\n",
    "        basic stats table at the top of the report \"\"\"\n",
    "\n",
    "        headers = OrderedDict()\n",
    "        headers['overall_alignment_rate'] = {\n",
    "            'title': '% Aligned',\n",
    "            'description': 'overall alignment rate',\n",
    "            'max': 100,\n",
    "            'min': 0,\n",
    "            'suffix': '%',\n",
    "            'scale': 'YlGn'\n",
    "        }\n",
    "        self.general_stats_addcols(self.bowtie2_data, headers)\n",
    "\n",
    "    def bowtie2_alignment_plot (self):\n",
    "        \"\"\" Make the HighCharts HTML to plot the alignment rates \"\"\"\n",
    "\n",
    "        half_warning = ''\n",
    "        for s_name in self.bowtie2_data:\n",
    "            if 'paired_aligned_mate_one_halved' in self.bowtie2_data[s_name] or 'paired_aligned_mate_multi_halved' in self.bowtie2_data[s_name] or 'paired_aligned_mate_none_halved' in self.bowtie2_data[s_name]:\n",
    "                half_warning = '<em>Please note that single mate alignment counts are halved to tally with pair counts properly.</em>'\n",
    "        description_text = 'This plot shows the number of reads aligning to the reference in different ways.'\n",
    "\n",
    "        # Config for the plot\n",
    "        config = {\n",
    "            'ylab': '# Reads',\n",
    "            'cpswitch_counts_label': 'Number of Reads'\n",
    "        }\n",
    "\n",
    "        # Two plots, don't mix SE with PE\n",
    "        if self.num_se > 0:\n",
    "            sekeys = OrderedDict()\n",
    "            sekeys['unpaired_aligned_one'] = { 'color': '#20568f', 'name': 'SE mapped uniquely' }\n",
    "            sekeys['unpaired_aligned_multi'] = { 'color': '#f7a35c', 'name': 'SE multimapped' }\n",
    "            sekeys['unpaired_aligned_none'] = { 'color': '#981919', 'name': 'SE not aligned' }\n",
    "            config['id'] = 'bowtie2_se_plot'\n",
    "            config['title'] = 'Bowtie 2: SE Alignment Scores'\n",
    "            self.add_section(\n",
    "                description = description_text,\n",
    "                helptext = '''\n",
    "                There are 3 possible types of alignment:\n",
    "                * **SE Mapped uniquely**: Read has only one occurence in the reference genome.\n",
    "                * **SE Multimapped**: Read has multiple occurence.\n",
    "                * **SE No aligned**: Read has no occurence.\n",
    "                ''',\n",
    "                plot = bargraph.plot(self.bowtie2_data, sekeys, config)\n",
    "            )\n",
    "\n",
    "        if self.num_pe > 0:\n",
    "            pekeys = OrderedDict()\n",
    "            pekeys['paired_aligned_one'] = { 'color': '#20568f', 'name': 'PE mapped uniquely' }\n",
    "            pekeys['paired_aligned_discord_one'] = { 'color': '#5c94ca', 'name': 'PE mapped discordantly uniquely' }\n",
    "            pekeys['paired_aligned_mate_one_halved'] = { 'color': '#95ceff', 'name': 'PE one mate mapped uniquely' }\n",
    "            pekeys['paired_aligned_multi'] = { 'color': '#f7a35c', 'name': 'PE multimapped' }\n",
    "            pekeys['paired_aligned_discord_multi'] = { 'color': '#dce333', 'name': 'PE discordantly multimapped' }\n",
    "            pekeys['paired_aligned_mate_multi_halved'] = { 'color': '#ffeb75', 'name': 'PE one mate multimapped' }\n",
    "            pekeys['paired_aligned_mate_none_halved'] = { 'color': '#981919', 'name': 'PE neither mate aligned' }\n",
    "            config['id'] = 'bowtie2_pe_plot'\n",
    "            config['title'] = 'Bowtie 2: PE Alignment Scores'\n",
    "            self.add_section(\n",
    "                description = \"<br>\".join([description_text,half_warning]),\n",
    "                helptext = '''\n",
    "                There are 6 possible types of alignment:\n",
    "                * **PE mapped uniquely**: Pair has only one occurence in the reference genome.\n",
    "                * **PE mapped discordantly uniquely**: Pair has only one occurence but not in proper pair.\n",
    "                * **PE one mate mapped uniquely**: One read of a pair has one occurence.\n",
    "                * **PE multimapped**: Pair has multiple occurence.\n",
    "                * **PE one mate multimapped**: One read of a pair has multiple occurence.\n",
    "                * **PE neither mate aligned**: Pair has no occurence.\n",
    "                ''',\n",
    "                plot = bargraph.plot(self.bowtie2_data, pekeys, config)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fh = open(\"figures/metadata.html\",\"w\")\n",
    "# fh.write(metadata.head(25).to_html())\n",
    "# fh.close()\n",
    "#A custom function to help us find the raw fastq files\n",
    "from glob import glob\n",
    "rawFastqFiles = glob('jgi_transfer/metaT_raw/*/Raw_Data/*')\n",
    "\n",
    "def lookupFSTQ(name,rawFastqFiles):\n",
    "    fastqName = ''\n",
    "    found = False\n",
    "    for fastqName in rawFastqFiles:\n",
    "        if name in fastqName: \n",
    "            found = True\n",
    "            break\n",
    "    if found:\n",
    "        rawFastqFiles.remove(fastqName)\n",
    "        return fastqName"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
